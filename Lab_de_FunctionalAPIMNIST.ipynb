{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/ebw3nt/blob/main/Lab_de_FunctionalAPIMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXnqYdN_2Ovy"
      },
      "source": [
        "# import tensorflow.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkTmc4FVJDAN"
      },
      "source": [
        "# Chargement des données MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous devez préparer un jeu de données pour entraîner un modèle de reconnaissance d’images de chiffres manuscrits.\n",
        ">\n",
        "> * Quelle bibliothèque Python pourriez-vous utiliser pour accéder à un dataset standard de chiffres manuscrits ?\n",
        "> * Écrivez le code permettant de **charger ce dataset** et de le séparer en données d’entraînement et de test.\n",
        "> * Assurez-vous que vos variables contiennent à la fois **les images** et **les labels correspondants**."
      ],
      "metadata": {
        "id": "hQJU4R8z6bxa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP-zdKaXIm5z",
        "outputId": "5ecc3d4d-4913-42d2-8db0-f0deea54d458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77ObZYZY2KFa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4DJ8s7cJKLa"
      },
      "source": [
        "# Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNBwgWDjI-yT"
      },
      "source": [
        "\"\"\"\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On travaille ici avec **le dataset MNIST**, qui contient des images de chiffres manuscrits (0 à 9) :\n",
        "\n",
        "* `train_images` → 60 000 images pour l’entraînement\n",
        "* `test_images` → 10 000 images pour le test\n",
        "\n",
        "Chaque image est initialement de taille **28x28 pixels**.\n",
        "\n",
        "---\n",
        "\n",
        "1. **`reshape((60000, 28*28))`**\n",
        "\n",
        "   * Chaque image 28x28 est transformée en un vecteur de 784 pixels (`28*28 = 784`).\n",
        "   * Pourquoi ? Les réseaux de neurones classiques (dense/fc) attendent **des vecteurs 1D**, pas des matrices 2D.\n",
        "\n",
        "2. **`astype('float32') / 255`**\n",
        "\n",
        "   * Les valeurs des pixels vont de 0 à 255 (entiers).\n",
        "   * On les convertit en **float32** et on les normalise entre 0 et 1.\n",
        "   * Pourquoi ? Les réseaux apprennent mieux et plus rapidement avec des données normalisées.\n",
        "\n",
        "---\n",
        "\n",
        "* Les labels initiaux sont des entiers de 0 à 9.\n",
        "* `to_categorical` les transforme en **vecteurs “one-hot”** :\n",
        "\n",
        "| label | one-hot               |\n",
        "| ----- | --------------------- |\n",
        "| 3     | [0,0,0,1,0,0,0,0,0,0] |\n",
        "\n",
        "* Pourquoi ? Les sorties du réseau utilisent **softmax**, qui calcule la probabilité pour chaque classe. Le one-hot est nécessaire pour calculer correctement la **loss** (erreur) pendant l’entraînement.\n",
        "\n",
        "1. **Images** : convertir les matrices 2D en vecteurs 1D et normaliser.\n",
        "2. **Labels** : convertir les entiers en vecteurs one-hot pour l’apprentissage multiclasses."
      ],
      "metadata": {
        "id": "ch__EC1U7K6X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2iztvr2J-Qq"
      },
      "source": [
        "# Définition du réseau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgv1ylhjJ7jS",
        "outputId": "f1e2fed9-ccce-4cf1-9bed-d35478f938ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "\"\"\"\n",
        "from keras import models\n",
        "from keras import layers\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* On crée un réseau simple à **2 couches** :\n",
        "\n",
        "  1. Une couche cachée avec 512 neurones pour apprendre les patterns.\n",
        "  2. Une couche de sortie avec 10 neurones pour prédire 10 classes.\n",
        "* Les images doivent être **aplatis** en vecteurs avant d’entrer dans le réseau.\n",
        "* La couche cachée utilise `ReLU` pour l’apprentissage, la couche finale `Softmax` pour produire des probabilités.\n",
        "\n",
        "---\n",
        "\n",
        "* `keras` est une bibliothèque Python pour créer et entraîner des **réseaux de neurones** facilement.\n",
        "* `models` contient des structures de réseaux (comme `Sequential`).\n",
        "* `layers` contient les **couches de neurones** que l’on peut ajouter à un réseau.\n",
        "\n",
        "---\n",
        "\n",
        "* `Sequential` signifie que les couches seront **empilées les unes après les autres**.\n",
        "* On construit un réseau **linéaire**, simple à comprendre et à entraîner.\n",
        "\n",
        "---\n",
        "\n",
        "### Première couche dense (fully connected)\n",
        "\n",
        "```python\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "```\n",
        "\n",
        "* `Dense` = **couche complètement connectée**, chaque neurone est relié à tous les neurones de la couche précédente.\n",
        "* `512` = nombre de neurones dans cette couche.\n",
        "* `activation='relu'` = fonction d’activation **ReLU** (Rectified Linear Unit), qui introduit de la **non-linéarité** pour permettre au réseau d’apprendre des relations complexes.\n",
        "* `input_shape=(28*28,)` = taille de l’entrée. Ici, on suppose que chaque entrée est une image de **28x28 pixels** aplatie en un vecteur de 784 valeurs : c’est comme donner au réseau une **liste de 784 valeurs** et lui demander de trouver des patterns.\n",
        "\n",
        "---\n",
        "\n",
        "### Couche de sortie\n",
        "\n",
        "```python\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "```\n",
        "\n",
        "* 10 neurones = **10 classes** à prédire (ex : chiffres de 0 à 9 si on travaille sur MNIST).\n",
        "* `activation='softmax'` = transforme les sorties en **probabilités** qui s’additionnent à 1.\n",
        "* Chaque neurone représente la probabilité que l’entrée appartienne à cette classe : la dernière couche **donne la décision finale du modèle** sous forme de probabilités."
      ],
      "metadata": {
        "id": "T4rGnMQ87yyk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B-SlLTF8MAO"
      },
      "source": [
        "## L'API fonctionnelle : définition du réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbJJ8roV9GwI"
      },
      "source": [
        "### Création d'un nœud d'entrée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMxB1gUk71P3"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# specify the shape of each data sample: 784-dimensional vectors\n",
        "inputs = keras.Input(shape=(784,), name='img')\n",
        "# the batch size is always omitted: inputs = keras.Input(shape=(784,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On définit une entrée de modèle qui attend des vecteurs de 784 valeurs, que l’on nomme `img`. Cette étape est nécessaire pour construire un modèle de type **Functional API** dans Keras :\n",
        "\n",
        "1. **`keras.Input()`** :\n",
        "\n",
        "   * C’est la manière dont on définit l’entrée d’un réseau de neurones dans Keras (qui fait partie de TensorFlow).\n",
        "   * On crée un point d’entrée pour les données que le modèle va recevoir.\n",
        "\n",
        "2. **`shape=(784,)`** :\n",
        "\n",
        "   * Cela décrit la forme des données attendues.\n",
        "   * Ici, `(784,)` signifie que chaque donnée d’entrée est un vecteur de **784 valeurs**.\n",
        "   * Typiquement, c’est utilisé pour des images 28x28 pixels (comme dans le dataset MNIST) que l’on a **aplatis** en un vecteur unique : 28 × 28 = 784.\n",
        "\n",
        "3. **`name='img'`** :\n",
        "\n",
        "   * On donne un nom à cette entrée pour pouvoir la référencer plus facilement dans le modèle ou lors de la visualisation de l’architecture."
      ],
      "metadata": {
        "id": "owrSf27f-wrV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wOGi0TH9S68"
      },
      "source": [
        "### Informations à fournir au modèle (autre méthode)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIMfp4kH9lFM"
      },
      "source": [
        "\"\"\"\n",
        "inputs.shape = TensorShape([None, 784])\n",
        "inputs.dtype = tf.float32\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On prépare un ensemble de données où chaque exemple est un vecteur de 784 valeurs flottantes, et on peut traiter n’importe quel nombre d’exemples à la fois.\n",
        "\n",
        "Ici, `inputs` représente les **données d’entrée** pour un modèle (par exemple, des images aplaties d’un dataset comme MNIST).\n",
        "\n",
        "---\n",
        "\n",
        "* `shape` signifie la **forme** du tenseur (c’est-à-dire sa dimension).\n",
        "* `[None, 784]` indique que :\n",
        "\n",
        "  * `784` → chaque donnée d’entrée a 784 **éléments**, par exemple une image de 28×28 pixels aplatie.\n",
        "  * `None` → le nombre d’exemples peut varier, donc on ne le fixe pas à l’avance.\n",
        "* En pratique : on peut envoyer **n’importe quel nombre d’images** à la fois au modèle.\n",
        "\n",
        "Les calculs dans les réseaux de neurones nécessitent souvent des flottants pour être précis et efficaces :\n",
        "* `dtype` signifie **type de données**.\n",
        "* `tf.float32` → chaque élément du tenseur est un nombre en **32 bits à virgule flottante**."
      ],
      "metadata": {
        "id": "_U-Ba_FR_ri7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAELFcoJ965f"
      },
      "source": [
        "### Créer un nouveau nœud dans le graphe des couches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErYFbrQs-Fwt"
      },
      "source": [
        "# calling a layer on this inputs object\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# drawing an arrow from \"inputs\" to this layer we created\n",
        "dense = layers.Dense(64, activation='relu')\n",
        "# \"passing\" the inputs to the dense layer, and out we get x\n",
        "x = dense(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`inputs` représente les données d’entrée que le réseau va traiter (par exemple, des caractéristiques d’un client, d’une image, etc.).\n",
        "\n",
        "### Étape 1 : Créer une couche Dense\n",
        "\n",
        "```python\n",
        "dense = layers.Dense(64, activation='relu')\n",
        "```\n",
        "\n",
        "* `Dense` est une couche **complètement connectée**, c’est-à-dire que chaque neurone de cette couche est connecté à tous les neurones de la couche précédente.\n",
        "* `64` indique le **nombre de neurones** dans cette couche.\n",
        "* `activation='relu'` applique la fonction d’activation **ReLU**, qui transforme les valeurs pour ajouter de la non-linéarité et aider le réseau à apprendre des relations complexes.\n",
        "\n",
        "---\n",
        "\n",
        "### Étape 2 : “Passer” les données à travers la couche\n",
        "\n",
        "```python\n",
        "x = dense(inputs)\n",
        "```\n",
        "\n",
        "* Ici, on **applique la couche Dense à nos données d’entrée** (`inputs`).\n",
        "* En d’autres termes, les données passent dans tous les neurones de cette couche, avec les poids initiaux.\n",
        "* La sortie est stockée dans `x`, qui est une **nouvelle représentation de nos données**, enrichie par la transformation de la couche Dense."
      ],
      "metadata": {
        "id": "_EWXA3T0Arnr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INrUXTjd-t-U"
      },
      "source": [
        "### Ajouter quelques couches supplémentaires au graphe des couches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh-HvG-k_A8J"
      },
      "source": [
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* La première couche (`relu`) apprend des **représentations internes**.\n",
        "* La deuxième couche (`softmax`) transforme ces représentations en **décision finale** sous forme de probabilités.\n",
        "\n",
        "---\n",
        "\n",
        "1. **`x = layers.Dense(64, activation='relu')(x)`**\n",
        "\n",
        "   * Ici, on crée une **couche dense** (fully connected) avec **64 neurones**.\n",
        "   * Chaque neurone reçoit toutes les sorties de la couche précédente.\n",
        "   * L’activation `relu` signifie que chaque neurone renvoie zéro si l’entrée est négative, et la valeur elle-même si elle est positive.\n",
        "   * En pratique : cette couche va apprendre à extraire des **caractéristiques utiles** pour notre tâche (ex: classification d’images ou de textes).\n",
        "\n",
        "2. **`outputs = layers.Dense(10, activation='softmax')(x)`**\n",
        "\n",
        "   * On crée une deuxième couche dense, mais cette fois avec **10 neurones**, correspondant au **nombre de classes à prédire**.\n",
        "   * L’activation `softmax` transforme les sorties en **probabilités**, donc chaque neurone donne la probabilité que l’entrée appartienne à une classe particulière.\n",
        "   * En pratique : le réseau va prédire **quelle classe est la plus probable** pour chaque exemple."
      ],
      "metadata": {
        "id": "0KfjTm6HBhQg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdpKQSuV_X8P"
      },
      "source": [
        "### Créer un modèle en spécifiant ses entrées et ses sorties dans le graphe des couches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YJ5xl7n_d3T"
      },
      "source": [
        "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans Keras, on définit un **modèle** en précisant ses **entrées** (`inputs`) et ses **sorties** (`outputs`). C’est ainsi que le framework sait comment connecter les différentes couches entre elles et comment faire passer les données.\n",
        "\n",
        "---\n",
        "\n",
        "* `inputs=inputs` : on indique quelles sont les **données d’entrée** du modèle (ex. des images de chiffres pour MNIST).\n",
        "* `outputs=outputs` : on indique la **sortie attendue** du modèle (ex. les probabilités pour chaque chiffre de 0 à 9).\n",
        "* `name='mnist_model'` : on **donne un nom** au modèle, ce qui est pratique pour l’identification et le suivi, notamment si on a plusieurs modèles dans un projet.\n",
        "\n",
        "> Sans le nom, Keras attribue un nom générique automatiquement (`model_1`, `model_2`, …). Ici, on choisit un nom explicite pour mieux suivre le modèle dans le code et dans les rapports."
      ],
      "metadata": {
        "id": "DlRzwLOXCY-6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7bcSDA8BnbR"
      },
      "source": [
        "### Processus de définition du modèle complet (rappel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvxeRj0IBs-2"
      },
      "source": [
        "\"\"\"\n",
        "inputs = keras.Input(shape=(784,), name='img')\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqAAJwSB_ZGg"
      },
      "source": [
        "### Afficher les formes d'entrée et de sortie de chaque couche"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQSnY1dvDYAn"
      },
      "source": [
        "keras.utils.plot_model(model, 'my_fist_model_with_shape_info.png', \\\n",
        "                       show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "keras.utils.plot_model(model, 'my_fist_model_with_shape_info.png', show_shapes=True)\n",
        "```\n",
        "\n",
        "sert à **visualiser l’architecture d’un modèle Keras** sous forme de schéma :\n",
        "\n",
        "1. **`keras.utils.plot_model`**\n",
        "\n",
        "   * C’est une fonction utilitaire de Keras.\n",
        "   * Elle permet de créer une image qui représente les différentes couches du modèle, comment elles sont connectées, et éventuellement leurs dimensions.\n",
        "\n",
        "2. **`model`**\n",
        "\n",
        "   * C’est le modèle Keras que vous avez créé (par exemple un `Sequential` ou un modèle fonctionnel).\n",
        "   * La fonction va analyser ses couches et leur enchaînement.\n",
        "\n",
        "3. **`'my_fist_model_with_shape_info.png'`**\n",
        "\n",
        "   * C’est le nom du fichier image qui sera généré.\n",
        "   * Ici, le schéma sera sauvegardé sur votre disque avec ce nom.\n",
        "\n",
        "4. **`show_shapes=True`**\n",
        "\n",
        "   * Cela demande à afficher **la taille des tenseurs** (les dimensions des données) à chaque couche du modèle.\n",
        "   * Par exemple, pour une couche Dense qui reçoit un vecteur de taille 128 et produit un vecteur de taille 64, vous verrez `(128,) -> (64,)`.\n",
        "   * Très utile pour **vérifier que les dimensions correspondent** tout au long du réseau.\n",
        "\n",
        "---\n",
        "\n",
        "* Permet de **visualiser rapidement la structure** d’un modèle complexe.\n",
        "* Aide à **diagnostiquer des erreurs de dimension**.\n",
        "* Utile pour **documenter vos modèles** dans un rapport ou une présentation."
      ],
      "metadata": {
        "id": "pUGXbS6TFTtQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUkbevb-EjgW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u44zZ3OFKiT6"
      },
      "source": [
        "# Définition de l'optimiseur et de la fonction de perte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_7VGt2pKedh",
        "outputId": "b83b8bed-bb2a-42b6-84ec-ab736526fa7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "\"\"\"\n",
        "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', \\\n",
        "                metrics=['accuracy'])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette ligne prépare le réseau pour l’entraînement, en lui disant comment apprendre (`optimizer`), comment mesurer son erreur (`loss`) et comment suivre ses performances (`metrics`).\n",
        "\n",
        "1. **`network.compile()`**\n",
        "   Cette fonction dit au réseau : *« Voici comment tu dois apprendre et comment évaluer tes résultats »*.\n",
        "   C’est une étape obligatoire avant de lancer l’entraînement (`network.fit()`).\n",
        "\n",
        "2. **`optimizer='rmsprop'`**\n",
        "   L’optimiseur contrôle **la façon dont le réseau ajuste ses paramètres** pour mieux prédire.\n",
        "\n",
        "   * `rmsprop` est un algorithme efficace, souvent utilisé pour les réseaux de neurones qui traitent des données séquentielles ou avec beaucoup de paramètres.\n",
        "\n",
        "3. **`loss='categorical_crossentropy'`**\n",
        "   La fonction de perte mesure **l’écart entre les prédictions du réseau et la réalité**.\n",
        "\n",
        "   * `categorical_crossentropy` est adaptée quand on a **plusieurs classes possibles** (classification multiple). Par exemple, reconnaître le type de fruit parmi pomme, banane, orange.\n",
        "\n",
        "4. **`metrics=['accuracy']`**\n",
        "   Les métriques permettent de suivre **la performance du modèle pendant l’entraînement**.\n",
        "\n",
        "   * `accuracy` signifie qu’on regarde le **pourcentage de prédictions correctes**."
      ],
      "metadata": {
        "id": "eVDTiRsYGPix"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgSKfw6tKviD"
      },
      "source": [
        "# Training the network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtn78lXoK52K",
        "outputId": "7ae9c598-caf3-4359-f900-b25a32712a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.2585 - acc: 0.9250\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1041 - acc: 0.9680\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0685 - acc: 0.9792\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0491 - acc: 0.9856\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0369 - acc: 0.9890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc24ca22d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMHLKWKnLjjJ"
      },
      "source": [
        "### Test du réseau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5QmqKyLLfed",
        "outputId": "8c7cf18b-131e-4829-801f-c5c14e67927d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 52us/step\n",
            "test_acc: 0.9773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3bFfo9hEYN0"
      },
      "source": [
        "# demo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construire et entraîner un réseau de neurones pour classer les images de chiffres manuscrits (0 à 9) du dataset MNIST.\n",
        "\n",
        "**Consignes :**\n",
        "\n",
        "1. Chargez le dataset MNIST depuis `keras.datasets`.\n",
        "2. Préparez les données :\n",
        "\n",
        "   * Transformez chaque image en vecteur plat (`flatten`) de taille 784.\n",
        "   * Normalisez les valeurs des pixels pour qu’elles soient comprises entre 0 et 1.\n",
        "3. Créez un modèle Keras adapté à la classification de 10 classes.\n",
        "4. Compilez le modèle en utilisant :\n",
        "\n",
        "   * une fonction de perte adaptée aux labels entiers,\n",
        "   * un optimiseur de votre choix,\n",
        "   * et l’accuracy comme métrique.\n",
        "5. Entraînez le modèle sur le train set avec un `batch_size` de 64, pour 5 époques, et utilisez 20% des données pour la validation.\n",
        "6. Évaluez votre modèle sur le test set et affichez la **loss** et l’**accuracy**.\n",
        "\n",
        "**Bonus (optionnel) :**\n",
        "\n",
        "* Essayez différents optimisateurs et comparez les performances.\n",
        "* Tracez la courbe de loss et d’accuracy pendant l’entraînement."
      ],
      "metadata": {
        "id": "PlfmSDbXHP9E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXRN969OEc_y"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkz2Wrj6JdcD"
      },
      "source": [
        "# Sauvegarde et sérialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIZB2ip8Jkjy"
      },
      "source": [
        "model.save('path_to_my_model.h5')\n",
        "\n",
        "# Recreate the exact same model purely from the file\n",
        "model = keras.models.load_model('path_to_my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lorsqu’on entraîne un modèle Keras/TensorFlow, le fichier .h5 peut stocker :\n",
        "- La structure du modèle (les couches, leurs connexions)\n",
        "- Les poids entraînés (paramètres appris par le modèle)\n",
        "- Les configurations d’entraînement (optimizer, métriques, etc.)\n",
        "\n",
        "Ainsi, on peut sauvegarder et recharger un modèle complet facilement."
      ],
      "metadata": {
        "id": "xozBY0P4IcUI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lhX5ttuKTTA"
      },
      "source": [
        "# Modèle d'auto-encodeur de bout en bout pour l'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zdc0aTRKVIL"
      },
      "source": [
        "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
        "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On construit ici un **encodeur de réseau de neurones convolutif (CNN)**. L’objectif est de transformer une image en une représentation compacte (ou \"embedding\") qu’un modèle peut utiliser pour classification, reconstruction ou autre tâche.\n",
        "\n",
        "---\n",
        "\n",
        "### Étapes\n",
        "\n",
        "1. **Définir l’entrée**\n",
        "\n",
        "```python\n",
        "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
        "```\n",
        "\n",
        "* On crée un **point d’entrée** pour le modèle.\n",
        "* `shape=(28, 28, 1)` signifie :\n",
        "\n",
        "  * Hauteur : 28 pixels\n",
        "  * Largeur : 28 pixels\n",
        "  * Canaux : 1 (donc image en **niveau de gris**)\n",
        "* `name='img'` donne un nom à cet input pour plus de clarté dans le modèle.\n",
        "\n",
        "---\n",
        "\n",
        "2. **Premières convolutions**\n",
        "\n",
        "```python\n",
        "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "```\n",
        "\n",
        "* Chaque `Conv2D` applique un **filtre convolutif** pour extraire des **caractéristiques locales** (bords, textures…).\n",
        "* `16` puis `32` : nombre de **filtres**, donc combien de types de motifs on détecte.\n",
        "* `3` : taille du filtre (3×3 pixels).\n",
        "* `activation='relu'` : fonction ReLU pour introduire de la **non-linéarité**, ce qui aide le réseau à apprendre des motifs complexes.\n",
        "\n",
        "---\n",
        "\n",
        "3. **Réduction de la dimension spatiale**\n",
        "\n",
        "```python\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "```\n",
        "\n",
        "* Le **max pooling** réduit la taille de l’image en ne conservant que la valeur maximale dans chaque fenêtre 3×3.\n",
        "* Avantages :\n",
        "\n",
        "  * Réduit le nombre de paramètres\n",
        "  * Rend le modèle moins sensible aux petites translations\n",
        "  * Accélère l’entraînement\n",
        "\n",
        "---\n",
        "\n",
        "4. **Convolutions supplémentaires**\n",
        "\n",
        "```python\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(16)(x)\n",
        "```\n",
        "\n",
        "* On ajoute d’autres couches pour **apprendre des motifs plus complexes**.\n",
        "* La dernière couche (`Conv2D(16)`) prépare les données pour l’étape suivante (souvent un **flatten** ou un **bottleneck** si c’est un autoencodeur).\n",
        "\n",
        "---\n",
        "\n",
        "* **Input** → reçoit l’image.\n",
        "* **Conv2D** → extrait des caractéristiques locales.\n",
        "* **MaxPooling2D** → réduit la taille, conserve l’essentiel.\n",
        "* **Conv2D finale** → crée une représentation compacte et riche de l’image.\n"
      ],
      "metadata": {
        "id": "MGZitnQpJRxc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQPxpWm1SxzG"
      },
      "source": [
        "## Prédire la classe d'un exemple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfzvAcITLyCA"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkvGic1vTs_0",
        "outputId": "ade3511e-d1b8-4909-a1ea-d26e083dbcb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "plt.imshow(test_images [0])\n",
        "# img = test_images [0].reshape ((1, 28 * 28))\n",
        "# il faut aussi faire la division par 255 si on prend les exemples de base\n",
        "test_images = test_images.astype('float32') / 255\n",
        "img = test_images[0].reshape((1, 28 * 28))\n",
        "print(network.predict(img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.79732190e-09 4.55667948e-10 2.60996075e-07 1.15134244e-04\n",
            "  2.53462399e-12 3.58231533e-09 6.89178363e-15 9.99883175e-01\n",
            "  9.71018608e-08 1.36982396e-06]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}