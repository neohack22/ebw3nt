{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/ebw3nt/blob/main/modelisation/Version_TPU_de_Keras_de_Impl%C3%A9mentationCBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl9nmloVpySE"
      },
      "source": [
        "# Analyse de Sentiment IMDB: Comparaison PyTorch vs Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f903d9fa"
      },
      "source": [
        "L'objectif est de mettre en place un classificateur simple pour l'analyse de texte et de sentiment. La tâche est la classification binaire des critiques de films. L'ensemble de données fait partie du jeu de données `imdb`. Vous pouvez trouver l'ensemble de données original sur le [site web d'imdb](https://www.imdb.com/interfaces/) ou une version sur le [site web de kaggle](https://www.kaggle.com/utathya/imdb-review-dataset). Pour cette session de laboratoire, nous utiliserons une version prétraitée.\n",
        "\n",
        "La feuille de route est :\n",
        "\n",
        "*   Charger, nettoyer et configurer les données (en pratique, c'est une étape très importante, pour ce laboratoire, nous la sautons).\n",
        "*   Les rendre adaptées aux modèles PyTorch\n",
        "*   Définir votre propre modèle\n",
        "*   Expériences\n",
        "\n",
        "## Les données\n",
        "\n",
        "Les jeux de données sont disponibles dans le dépôt cloud. Il y a 2 fichiers, un pour les critiques positives (`imdb.pos`) et un pour les négatives (`imdb.neg`). Il y a 300 000 exemples de chaque classe.\n",
        "\n",
        "Voici deux fonctions pour charger et nettoyer les données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aLVRPoUpySK",
        "outputId": "c5a27f1c-3e71-496e-b322-32c359f89ce9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f57a2a39350>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pytorch\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.autograd as ag\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "th.manual_seed(1) # set the seed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KERAS\n",
        "\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-H_Z0h5mx4U",
        "outputId": "41489fe7-91a0-4d4a-94af-d0bf02a7a1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.33.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.46.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.3.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m780.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.46.3-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, google_pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.12.19 google_pasta-0.2.0 libclang-18.1.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.5 wheel-0.46.3\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement gzip (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for gzip\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras\n",
        "\n",
        "import re # Identique pour les expressions régulières\n",
        "import numpy as np # Identique pour les opérations numériques\n",
        "import tensorflow as tf # La bibliothèque principale de TensorFlow\n",
        "\n",
        "from tensorflow import keras # Le module Keras de TensorFlow\n",
        "from tensorflow.keras import layers # Pour les couches de modèles (Embedding, Dense, etc.)\n",
        "from tensorflow.keras import models # Pour construire des modèles (Model, Sequential)\n",
        "from tensorflow.keras import losses # Pour les fonctions de perte\n",
        "from tensorflow.keras import optimizers # Pour les optimiseurs\n",
        "\n",
        "import random # Identique pour les opérations aléatoires générales\n",
        "import math # Identique pour les opérations mathématiques\n",
        "import pickle # Identique pour la sérialisation des objets Python\n",
        "import gzip # Identique pour la compression de fichiers\n",
        "\n",
        "# Définir les graines pour la reproductibilité dans TensorFlow/Keras\n",
        "tf.random.set_seed(1) # Pour TensorFlow/Keras\n",
        "\n",
        "np.random.seed(1) # Pour NumPy\n",
        "random.seed(1) # Pour le module Python random"
      ],
      "metadata": {
        "id": "EDmMKIxIaArX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6183f706-c942-4cf9-b977-9f2997bf8b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c50839df"
      },
      "source": [
        "## Chargement des données\n",
        "\n",
        "Chargez les données :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K59vHLBpySN",
        "outputId": "83a88975-faa5-4aca-a9e5-c939e6effc6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-17 03:25:41--  https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.195.138, 74.125.195.102, 74.125.195.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.195.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA&export=download [following]\n",
            "--2026-02-17 03:25:41--  https://drive.usercontent.google.com/download?id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1552309 (1.5M) [application/octet-stream]\n",
            "Saving to: ‘imdb.pck.gz’\n",
            "\n",
            "imdb.pck.gz         100%[===================>]   1.48M  --.-KB/s    in 0.006s  \n",
            "\n",
            "2026-02-17 03:25:42 (241 MB/s) - ‘imdb.pck.gz’ saved [1552309/1552309]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# idem\n",
        "\n",
        "# find the file imdb.pck.gz, and set the next variable accordingly\n",
        "filename = 'imdb.pck.gz'\n",
        "\n",
        "# You can download the file with the following line:\n",
        "! wget \"https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\" -O imdb.pck.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91efe0e4"
      },
      "source": [
        "Ouvrez les données avec Python et vous obtiendrez 3 objets :\n",
        "\n",
        "*   `texts` : une liste de tenseurs, chaque tenseur représente une séquence de mots à classifier.\n",
        "*   `labels` : la classe, positive ou négative, du texte correspondant.\n",
        "*   `lexicon` : un dictionnaire pour mapper les entiers aux mots réels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlMFMQ08pySO",
        "outputId": "fe92afd4-e460-4f17-f6c7-ad685197d378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'torch.Tensor'> <class 'dict'>\n",
            "tensor([ 36,  25, 381,  10,  58,  21,  83])\n",
            "nb examples :  30000\n",
            "Vocab size:  5002\n"
          ]
        }
      ],
      "source": [
        "# idem\n",
        "\n",
        "fp = gzip.open(filename,'rb')\n",
        "texts , labels, lexicon  = pickle.load(fp)\n",
        "\n",
        "print(type(texts), type(labels), type(lexicon))\n",
        "print(texts[0])\n",
        "print(\"nb examples : \", len(texts))\n",
        "VOCAB_SIZE = len(lexicon)\n",
        "print(\"Vocab size: \", VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3feae9d7"
      },
      "source": [
        "Le fichier `imdb.pck.gz` est comme une boîte qui contient des objets `torch.Tensor` (des tenseurs PyTorch). Pour ouvrir cette boîte et comprendre ce qu'il y a dedans, Python a besoin de 'savoir parler' PyTorch, d'où l'importation nécessaire de `import torch as th`. Cette étape est une **dépendance du format du fichier source**, et non de votre choix de framework pour la modélisation.\n",
        "\n",
        "Une fois que ces tenseurs PyTorch sont chargés en mémoire, nous les convertissons immédiatement en tableaux NumPy (`.numpy()`), car NumPy est le langage 'natif' que Keras comprend le mieux pour les données. À partir de là, tout le reste de votre code pourra être purement Keras/TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94a45552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d03ccb5-9ec0-49db-8f01-eefcb9053a87"
      },
      "source": [
        "# keras\n",
        "\n",
        "# IMPORTANT : L'import de 'torch' est nécessaire ICI car le fichier 'imdb.pck.gz'\n",
        "# contient des objets qui ont été SÉRIALISÉS sous forme de tenseurs PyTorch.\n",
        "# Sans cet import, Python ne peut pas désérialiser correctement ces objets.\n",
        "import torch as th\n",
        "\n",
        "print(\"--- Étape de Chargement et Préparation des Données pour Keras ---\")\n",
        "\n",
        "# 1. Chargement des objets bruts depuis le fichier (Dépend du format de sauvegarde du fichier)\n",
        "# Les objets récupérés ici seront des torch.Tensor car le fichier a été sauvegardé ainsi.\n",
        "with gzip.open(filename,'rb') as fp:\n",
        "    raw_texts_from_file , raw_labels_from_file, lexicon_for_keras  = pickle.load(fp)\n",
        "\n",
        "print(f\"Type des objets après chargement brut : texts est une liste de {type(raw_texts_from_file[0])}\")\n",
        "print(f\"Type des objets après chargement brut : labels est de type {type(raw_labels_from_file)}\")\n",
        "\n",
        "# 2. Conversion explicite des tenseurs PyTorch en tableaux NumPy pour Keras\n",
        "# Keras (basé sur TensorFlow) travaille nativement avec des tableaux NumPy ou des tf.Tensor.\n",
        "labels_for_keras = raw_labels_from_file.numpy() # Convertir le tenseur PyTorch en tableau NumPy\n",
        "texts_for_keras = [t.numpy() for t in raw_texts_from_file] # Convertir chaque tenseur de la liste\n",
        "\n",
        "print(\"\\n--- Objets prêts pour Keras (format NumPy) ---\")\n",
        "print(f\"Type final pour Keras : texts_for_keras est une liste de {type(texts_for_keras[0])}\")\n",
        "print(f\"Type final pour Keras : labels_for_keras est de type {type(labels_for_keras)}\")\n",
        "print(f\"Type de 'lexicon': {type(lexicon_for_keras)}\")\n",
        "\n",
        "print(\"Exemple de texts_for_keras[0]:\", texts_for_keras[0])\n",
        "print(\"Nombre d'exemples : \", len(texts_for_keras))\n",
        "VOCAB_SIZE_KERAS = len(lexicon_for_keras)\n",
        "print(\"Taille du vocabulaire: \", VOCAB_SIZE_KERAS)\n",
        "\n",
        "# Il est recommandé de libérer la mémoire des objets PyTorch bruts si non utilisés\n",
        "del raw_texts_from_file, raw_labels_from_file\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Étape de Chargement et Préparation des Données pour Keras ---\n",
            "Type des objets après chargement brut : texts est une liste de <class 'torch.Tensor'>\n",
            "Type des objets après chargement brut : labels est de type <class 'torch.Tensor'>\n",
            "\n",
            "--- Objets prêts pour Keras (format NumPy) ---\n",
            "Type final pour Keras : texts_for_keras est une liste de <class 'numpy.ndarray'>\n",
            "Type final pour Keras : labels_for_keras est de type <class 'numpy.ndarray'>\n",
            "Type de 'lexicon': <class 'dict'>\n",
            "Exemple de texts_for_keras[0]: [ 36  25 381  10  58  21  83]\n",
            "Nombre d'exemples :  30000\n",
            "Taille du vocabulaire:  5002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bc63ba1"
      },
      "source": [
        "Notez qu'un nombre réduit de mots est sélectionné pour construire le vocabulaire. Les mots moins fréquents sont écartés et remplacés par une forme spécifique (*unk* pour inconnu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SlDfDuVpySQ",
        "outputId": "aad48a7d-0bd9-4c76-ad80-0892c15f02c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word of index 0  :  <pad>\n",
            "word of index 1  :  <unk>\n",
            "word of index 2  :  !\n",
            "word of index 3  :  the\n",
            "word of index 4  :  a\n",
            "word of index 5  :  of\n",
            "word of index 6  :  movie\n",
            "word of index 7  :  and\n",
            "word of index 8  :  this\n",
            "word of index 9  :  to\n"
          ]
        }
      ],
      "source": [
        "# IDEM\n",
        "\n",
        "for i in range(10):\n",
        "    print(\"word of index\", i , \" : \", lexicon[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08EvO2IfpySR"
      },
      "source": [
        "To read the text you can use for example the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUNU4tIdpySR",
        "outputId": "26aaa4f1-ed60-496f-f151-baedc638f5b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7])\n",
            "Some positive reviews\n",
            "------------\n",
            "['strong', 'drama']\n",
            "['please', 'remake', 'this', 'movie']\n",
            "['very', 'funny', '!']\n",
            "['great', 'series']\n",
            "['fun', 'movie']\n",
            "Some negative reviews\n",
            "------------\n",
            "['absolute', 'waste', 'of', 'time']\n",
            "['the', 'worst', 'movie', 'ever', 'made']\n",
            "['slow', 'motion', 'picture', 'that', 'did', \"n't\", 'get', 'to', 'the', 'point']\n",
            "['there', 'are', 'good', 'bad', 'movies', 'and', 'there', 'are', 'bad', 'bad', 'movies', 'this', 'one', 'is', 'a', 'real', 'stinker']\n",
            "['<unk>', 'so', 'bad', 'its', 'funny']\n",
            "-----------\n",
            "A random sentence: \n",
            "['you', 'definitely', 'need', 'to', 'see', 'this', 'movie']\n"
          ]
        }
      ],
      "source": [
        "# PYTORCH\n",
        "\n",
        "def idx2wordlist(idx_array,lexicon):\n",
        "    l = []\n",
        "    for i in idx_array:\n",
        "        l.append(lexicon[i.item()])\n",
        "    return l\n",
        "print(texts[0].shape)\n",
        "print(\"Some positive reviews\")\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "    print(\n",
        "        idx2wordlist(\n",
        "            texts[\n",
        "                i+50],lexicon)) # les critiques positives sont regroupées dans une certaine partie de la liste texts\n",
        "print(\"Some negative reviews\")\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "    print(\n",
        "        idx2wordlist(\n",
        "            texts[\n",
        "                -i-2000],lexicon)) # les critiques négatives sont stockées à la fin de la liste\n",
        "\n",
        "print(\"-----------\\nA random sentence: \")\n",
        "print(idx2wordlist(texts[104],lexicon))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afaa9dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87e57b1-602e-4d8b-b88c-2d9c57212f12"
      },
      "source": [
        "# keras\n",
        "\n",
        "def idx2wordlist_keras(idx_array, lexicon_keras):\n",
        "    l = []\n",
        "    for i in idx_array:\n",
        "        # .item() fonctionne pour les scalaires NumPy aussi\n",
        "        l.append(lexicon_keras[i.item()])\n",
        "    return l\n",
        "\n",
        "# Assurez-vous que texts_for_keras et lexicon_for_keras sont chargés et prêts\n",
        "# (comme dans la cellule précédente d'adaptation pour Keras)\n",
        "\n",
        "print(texts_for_keras[0].shape) # texts_for_keras est une liste de tableaux NumPy, qui ont aussi un .shape\n",
        "print(\"Some positive reviews (Keras data)\")\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "    print(\n",
        "        idx2wordlist_keras(\n",
        "            texts_for_keras[\n",
        "                i+50], lexicon_for_keras)) # Utilisation de texts_for_keras et lexicon_for_keras\n",
        "print(\"Some negative reviews (Keras data)\")\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "    print(\n",
        "        idx2wordlist_keras(\n",
        "            texts_for_keras[\n",
        "                -i-2000], lexicon_for_keras)) # Utilisation de texts_for_keras et lexicon_for_keras\n",
        "\n",
        "print(\"-----------\\nA random sentence (Keras data): \")\n",
        "print(idx2wordlist_keras(texts_for_keras[104], lexicon_for_keras))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7,)\n",
            "Some positive reviews (Keras data)\n",
            "------------\n",
            "['strong', 'drama']\n",
            "['please', 'remake', 'this', 'movie']\n",
            "['very', 'funny', '!']\n",
            "['great', 'series']\n",
            "['fun', 'movie']\n",
            "Some negative reviews (Keras data)\n",
            "------------\n",
            "['absolute', 'waste', 'of', 'time']\n",
            "['the', 'worst', 'movie', 'ever', 'made']\n",
            "['slow', 'motion', 'picture', 'that', 'did', \"n't\", 'get', 'to', 'the', 'point']\n",
            "['there', 'are', 'good', 'bad', 'movies', 'and', 'there', 'are', 'bad', 'bad', 'movies', 'this', 'one', 'is', 'a', 'real', 'stinker']\n",
            "['<unk>', 'so', 'bad', 'its', 'funny']\n",
            "-----------\n",
            "A random sentence (Keras data): \n",
            "['you', 'definitely', 'need', 'to', 'see', 'this', 'movie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab185226"
      },
      "source": [
        "*   **Variables de données** : Les appels à la fonction et les accès aux données utilisent désormais `texts_for_keras` et `lexicon_for_keras`, qui sont les variables que nous avons préparées spécifiquement au format NumPy pour Keras dans la cellule précédente.\n",
        "\n",
        "En bref, cette partie du code illustre comment les fonctions utilitaires génériques de traitement de données restent souvent les mêmes, peu importe le framework, tant que les formats de données sous-jacents (ici, les tableaux NumPy) sont compatibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtlcwqfQpySS"
      },
      "source": [
        "## Interface données/modèle\n",
        "En pratique, nous partons de textes bruts et nous devons les convertir en indices de mots. À cette étape, nous pouvons effectuer un prétraitement du texte, une tokenisation et un nettoyage des données. Dans le cas présent, c'est déjà fait. Mais dans la vie réelle, c'est une étape très importante.\n",
        "\n",
        "L'objectif est d'implémenter un classificateur CBOW (Continuous Bag of Words, ou un sac d'embeddings de mots). Cela signifie que la première couche du modèle gère les embeddings de mots.\n",
        "\n",
        "Le module Embedding de PyTorch est conçu à cet effet. Ce module attend en entrée un tableau ou une liste d'indices de mots. Pour cette session, l'objectif est de développer rapidement un modèle. L'interface de données est donc plutôt simple. Nous terminons cette section en créant des labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f2e94a5"
      },
      "source": [
        "## Un premier modèle\n",
        "\n",
        "Le premier modèle est un CBOW (Continuous Bag of Words). Un texte est représenté comme un ensemble de mots (un sac de caractéristiques binaires) :\n",
        "\n",
        "- Chaque mot est associé à son embedding.\n",
        "- Le texte est représenté comme la somme des embeddings de mots impliqués.\n",
        "- Cette somme d'embeddings est ensuite alimentée à une couche linéaire avec une unité de sortie,\n",
        "- suivie par l'activation sigmoïde. La sortie du modèle est similaire à une régression logistique.\n",
        "\n",
        "Maintenant, nous voulons coder cela en PyTorch. Une façon est d'abord d'essayer de construire un tel modèle **étape par étape**, puis de créer une classe pour tout encapsuler dans un **modèle**.\n",
        "\n",
        "### Construction du modèle, étape par étape\n",
        "\n",
        "La couche d'entrée du modèle est une couche d'Embedding. Celle-ci est déjà implémentée dans PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q25KzwFlpySU",
        "outputId": "cd77d9d1-f5d7-45e7-d60c-980e4d6ce137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input:  tensor([ 21, 316, 320,   9,  59,   8,   6])\n",
            "length:  7\n",
            "Embs shape :  torch.Size([7, 4])\n",
            "tensor([[ 0.6971, -0.9576, -1.0220,  1.3295],\n",
            "        [ 1.0256,  1.7889, -1.2001,  0.8268],\n",
            "        [-1.1081,  0.4350, -0.5725, -1.6943],\n",
            "        [-0.9530, -1.2833, -0.6837,  1.3832],\n",
            "        [ 0.2081, -0.4403,  1.3717,  0.9725],\n",
            "        [-0.5415, -1.4216, -0.0367, -1.9919],\n",
            "        [-1.3417,  0.0124, -1.3485, -0.5739]], grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ],
      "source": [
        "# build an Embedding layer in Pytorch\n",
        "# it is important to understand the parameters given to the constructor !\n",
        "D = 4\n",
        "embLayer = th.nn.Embedding(num_embeddings=len(lexicon), embedding_dim=D)\n",
        "# The dim of 4 is a toy example.\n",
        "# run forward on some input\n",
        "inp = texts[104]\n",
        "embs = embLayer(inp) # embLayer.forward(inp)\n",
        "# Look at the dimension of i/o\n",
        "print(\"The input: \",inp)\n",
        "print(\"length: \",len(inp))\n",
        "print(\"Embs shape : \",embs.shape)\n",
        "print(embs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  `D = 4`: `D` représente la dimension de l'embedding, c'est-à-dire la taille du vecteur que chaque mot sera transformé. Ici, 4 est choisi comme un exemple simple.\n",
        "\n",
        "2.  `embLayer = th.nn.Embedding(num_embeddings=len(lexicon), embedding_dim=D)`: C'est la création de la couche d'embedding.\n",
        "    *   `num_embeddings=len(lexicon)`: C'est le nombre total de mots uniques dans votre vocabulaire. `len(lexicon)` donne la taille du vocabulaire que vous avez chargé précédemment (5002 dans cet exemple). Chaque mot de ce vocabulaire aura un vecteur d'embedding unique.\n",
        "    *   `embedding_dim=D`: C'est la dimension de chaque vecteur d'embedding. Chaque mot sera représenté par un vecteur de 4 nombres flottants.\n",
        "\n",
        "3.  `inp = texts[104]`: Cette ligne sélectionne un exemple d'entrée, qui est le 105ème texte (index 104) de votre ensemble de données `texts`. `inp` est un tenseur d'indices de mots, comme `tensor([ 21, 316, 320, 9, 59, 8, 6])`.\n",
        "\n",
        "4.  `embs = embLayer(inp)`: Cette ligne exécute la propagation avant (`forward pass`) de la couche d'embedding. Elle prend le tenseur d'indices de mots (`inp`) et pour chaque index de mot, elle lui attribue le vecteur d'embedding correspondant de la couche `embLayer`.\n",
        "\n",
        "5.  Si l'entrée a `N` mots (ici, 7 mots), la sortie `embs` aura la forme `[N, D]`, c'est-à-dire `[7, 4]`. Chaque ligne de ce tenseur de sortie est le vecteur d'embedding de dimension `D` (4) pour le mot correspondant dans l'entrée."
      ],
      "metadata": {
        "id": "C7sX4onr0SPP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAo2OntepySV"
      },
      "source": [
        "Maintenant, nous voulons compresser le tenseur résultant le long de la dimension temporelle.\n",
        "Dans le traitement du langage naturel (NLP) et les architectures de réseaux de neurones qui traitent des séquences (comme les RNN, LSTM, Transformers), on parle souvent de la \"dimension de la séquence\" ou de la \"longueur de la séquence\" pour désigner cette dimension qui représente la succession des éléments (mots, caractères, tokens) dans le temps ou l'ordre.\n",
        "\n",
        "Le terme \"temporelle\" est très pertinent car il évoque l'idée d'une série de points de données qui se suivent, comme une série temporelle. Quand on traite un texte, on le considère comme une séquence d'événements (les mots) qui arrivent dans un certain ordre, d'où l'analogie avec le temps.\n",
        "\n",
        "Cette dimension dépend des textes d'entrée, alors que nous voulons construire une représentation de taille fixe de la phrase. La somme est une première idée.\n",
        "En additionnant les vecteurs de chaque mot, vous combinez leurs informations sémantiques. Le vecteur résultant est une sorte de \"moyenne\" ou de \"résumé\" de tous les mots présents dans la phrase. Il perd l'information sur l'ordre exact des mots, mais conserve l'information sur les mots qui étaient présents et leurs caractéristiques globales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df5786fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8cb462-6b85-49d0-e352-63fe4061e823"
      },
      "source": [
        "# build an Embedding layer in Keras\n",
        "# D is the embedding dimension, we use the same as the PyTorch example for direct comparison\n",
        "D_keras = 4\n",
        "\n",
        "# lexicon_for_keras et VOCAB_SIZE_KERAS sont définis dans la cellule d'adaptation des données\n",
        "emb_layer_keras = keras.layers.Embedding(input_dim=VOCAB_SIZE_KERAS, output_dim=D_keras)\n",
        "\n",
        "# run forward on some input\n",
        "# texts_for_keras contient déjà les données sous forme de NumPy arrays\n",
        "inp_keras = texts_for_keras[104]\n",
        "\n",
        "# Pour Keras, les couches s'attendent généralement à une entrée batchée (même pour un seul exemple)\n",
        "# Donc, nous ajoutons une dimension de batch (batch_size=1)\n",
        "inp_keras_batched = np.expand_dims(inp_keras, axis=0)\n",
        "\n",
        "# Effectuer le passage avant (forward pass)\n",
        "embs_keras_batched = emb_layer_keras(inp_keras_batched) # emb_layer_keras.call(inp_keras_batched)\n",
        "\n",
        "# Retirer la dimension du batch pour l'affichage, pour comparer directement avec la sortie PyTorch originale\n",
        "embs_keras = tf.squeeze(embs_keras_batched, axis=0)\n",
        "\n",
        "# Look at the dimension of i/o\n",
        "print(\"The input (NumPy): \", inp_keras)\n",
        "print(\"length: \", len(inp_keras))\n",
        "print(\"Embs shape (Keras) : \", embs_keras.shape)\n",
        "print(embs_keras)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input (NumPy):  [ 21 316 320   9  59   8   6]\n",
            "length:  7\n",
            "Embs shape (Keras) :  (7, 4)\n",
            "tf.Tensor(\n",
            "[[ 0.03792583  0.02277488  0.00360626 -0.04416872]\n",
            " [ 0.00883637  0.0329697   0.00840785 -0.04305023]\n",
            " [-0.01492629 -0.01901884 -0.02802038 -0.03017336]\n",
            " [-0.0082077   0.00786048  0.03529478  0.02130631]\n",
            " [ 0.00259622 -0.02487297 -0.01616706  0.02925593]\n",
            " [ 0.00261338 -0.04302381 -0.04602699 -0.01775904]\n",
            " [ 0.02076641 -0.02659606  0.038443   -0.02329419]], shape=(7, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0a4abb3"
      },
      "source": [
        "1.  **Importations** :\n",
        "    *   PyTorch : `th.nn.Embedding`\n",
        "    *   Keras : `tf.keras.layers.Embedding`\n",
        "\n",
        "2.  **Paramètres du Constructeur** :\n",
        "    *   PyTorch : `num_embeddings` (taille du vocabulaire), `embedding_dim` (dimension de l'embedding).\n",
        "    *   Keras : `input_dim` (taille du vocabulaire), `output_dim` (dimension de l'embedding).\n",
        "    *   Les concepts sont les mêmes, juste les noms de paramètres changent.\n",
        "\n",
        "3.  **Taille du Vocabulaire (`len(lexicon)`)** :\n",
        "    *   Nous utilisons `VOCAB_SIZE_KERAS` qui a été calculé à partir de `lexicon_for_keras`, notre version du lexique préparée pour Keras.\n",
        "\n",
        "4.  **Préparation de l'entrée** :\n",
        "    *   PyTorch : Prend directement un tenseur d'indices (`inp = texts[104]`).\n",
        "    *   Keras : Les couches Keras sont conçues pour traiter des *lots* de données. Même si vous n'avez qu'un seul exemple (`inp_keras`), vous devez généralement ajouter une dimension de lot. `np.expand_dims(inp_keras, axis=0)` transforme l'entrée de `(sequence_length,)` à `(1, sequence_length)`.\n",
        "\n",
        "5.  **Passage Avant (Forward Pass)** :\n",
        "    *   PyTorch : `embs = embLayer(inp)` (l'objet `embLayer` est *callable*).\n",
        "    *   Keras : `embs_keras_batched = emb_layer_keras(inp_keras_batched)` (l'objet `emb_layer_keras` est également *callable*). La méthode `call` est appelée implicitement.\n",
        "\n",
        "6.  **Forme de la Sortie** :\n",
        "    *   PyTorch : Si l'entrée est `(sequence_length,)`, la sortie est `(sequence_length, embedding_dim)`.\n",
        "    *   Keras : Si l'entrée est `(batch_size, sequence_length)`, la sortie est `(batch_size, sequence_length, embedding_dim)`. C'est pourquoi nous utilisons `tf.squeeze(embs_keras_batched, axis=0)` pour retirer la dimension de batch `(1,)` et obtenir `(sequence_length, embedding_dim)` pour une comparaison directe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9aqQ9aJpySV",
        "outputId": "26197125-7c58-40e5-9456-ba7270543fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7])\n",
            "torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "# pytorch\n",
        "\n",
        "## compute the sum of out to create a vector of size \"embedding_dim\".\n",
        "## Of course it will be a tensor with one dimension set to \"embedding_dim\".\n",
        "sumOfEmbs = embs.sum(dim=1)\n",
        "print(sumOfEmbs.shape) # check the shape\n",
        "sumOfEmbs = embs.sum(dim=0)\n",
        "print(sumOfEmbs.shape) # check the shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e73c8c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbb7b89-4941-4983-d7c1-063f81ed7724"
      },
      "source": [
        "# keras\n",
        "\n",
        "# Rappel: embs_keras a la forme (sequence_length, D_keras)\n",
        "# Pour le CBOW, on somme généralement le long de la dimension de la séquence pour obtenir un vecteur unique\n",
        "# de taille D_keras.\n",
        "\n",
        "# Dans TensorFlow/Keras, 'tf.reduce_sum' est l'équivalent de '.sum()'\n",
        "# et l'argument 'axis' est utilisé pour spécifier la dimension à sommer.\n",
        "\n",
        "# La première tentative du code PyTorch était sum(dim=1), ce qui aurait réduit la dimension des embeddings\n",
        "# à une seule valeur par mot. Si embs_keras est de forme (N, D), sum(axis=1) donnerait (N,).\n",
        "# sum_along_embedding_dim_keras = tf.reduce_sum(embs_keras, axis=1)\n",
        "# print(\"Shape after summing along embedding dimension (axis=1): \", sum_along_embedding_dim_keras.shape)\n",
        "\n",
        "# Pour le CBOW, l'objectif est de sommer les embeddings de tous les mots pour obtenir un seul vecteur\n",
        "# de la taille de la dimension d'embedding. Cela correspond à sum(dim=0) dans PyTorch pour un tenseur (N,D).\n",
        "sumOfEmbs_keras = tf.reduce_sum(embs_keras, axis=0)\n",
        "\n",
        "print(\"Embs shape (Keras): \", embs_keras.shape)\n",
        "print(\"Shape after summing along sequence dimension (axis=0): \", sumOfEmbs_keras.shape)\n",
        "print(\"Somme des embeddings (Keras):\")\n",
        "print(sumOfEmbs_keras)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embs shape (Keras):  (7, 4)\n",
            "Shape after summing along sequence dimension (axis=0):  (4,)\n",
            "Somme des embeddings (Keras):\n",
            "tf.Tensor([ 0.04960421 -0.04990663 -0.00446253 -0.10788331], shape=(4,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95a51d8"
      },
      "source": [
        "1.  **Fonction de Somme** :\n",
        "    *   PyTorch : La méthode `.sum()` est appelée directement sur le tenseur (`embs.sum(dim=X)`).\n",
        "    *   Keras/TensorFlow : La fonction `tf.reduce_sum(tensor, axis=X)` est utilisée. Elle est plus générale et permet de sommer le long d'un ou plusieurs axes.\n",
        "\n",
        "2.  **Spécification de la Dimension** :\n",
        "    *   PyTorch : L'argument `dim` spécifie la dimension le long de laquelle la somme est effectuée (par exemple, `dim=0` pour le premier axe, `dim=1` pour le deuxième, etc.).\n",
        "    *   Keras/TensorFlow : L'argument `axis` spécifie l'axe ou les axes le long desquels la somme est effectuée. `axis=0` est équivalent à `dim=0`, `axis=1` à `dim=1`.\n",
        "\n",
        "3.  **L'objectif du CBOW** :\n",
        "    *   Dans le contexte du Continuous Bag of Words (CBOW), l'objectif est de représenter une séquence de mots par un *seul vecteur* qui est la somme (ou la moyenne) de leurs embeddings individuels. Pour un tenseur d'embeddings de forme `(longueur_sequence, dimension_embedding)`, cela signifie sommer les embeddings sur la dimension `longueur_sequence`.\n",
        "    *   La ligne `sumOfEmbs_keras = tf.reduce_sum(embs_keras, axis=0)` réalise exactement cela : elle somme les vecteurs d'embedding de chaque mot (`embs_keras` est de forme `[7, 4]`) le long du premier axe (l'axe des mots), ce qui donne un vecteur de forme `[4]` (la dimension de l'embedding).\n",
        "\n",
        "En bref, la fonctionnalité est la même, seule la syntaxe change de la méthode `.sum()` de PyTorch à la fonction `tf.reduce_sum()` de TensorFlow, avec `dim` devenant `axis`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fray2Zj_pySW"
      },
      "source": [
        "La couche finale est une transformation linéaire : en entrée, nous avons un vecteur de taille embedding_dim et 1 en sortie. Codons cette transformation et vérifions la forme du résultat final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA4Ekg8ypySW",
        "outputId": "8ac98391-4be8-466d-98ef-8190c74e61d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1]) tensor([0.6601], grad_fn=<SigmoidBackward>)\n",
            "torch.Size([1]) tensor([0.8424], grad_fn=<SigmoidBackward>)\n"
          ]
        }
      ],
      "source": [
        "# pytorch\n",
        "\n",
        "# Compute out, after you created the Linear layer\n",
        "th.manual_seed(12) # set the seed\n",
        "W  = th.nn.Linear(in_features=D, out_features=1) # création de la couche linéaire.\n",
        "\n",
        "out_activation = th.nn.Sigmoid()\n",
        "out= out_activation( # Le résultat de la couche linéaire est passé à la fonction Sigmoïde\n",
        "    W(sumOfEmbs)) # notre représentation fixe de la phrase est passée à la couche linéaire W\n",
        "print(out.shape,out)\n",
        "\n",
        "W  = th.nn.Linear(in_features=D, out_features=1)\n",
        "out_activation = th.nn.Sigmoid()\n",
        "out= out_activation(W(sumOfEmbs))\n",
        "print(out.shape,out)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction Sigmoïde prend n'importe quelle valeur réelle et la compresse dans l'intervalle [0, 1]. Dans un contexte de classification binaire, cela peut être interprété comme la probabilité que l'entrée appartienne à la classe positive."
      ],
      "metadata": {
        "id": "8lbgSjOc6Cf2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25faf396",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff91bd21-200b-4d93-8f22-bd995ccb6401"
      },
      "source": [
        "# keras\n",
        "\n",
        "# Définir la graine pour la reproductibilité dans TensorFlow/Keras\n",
        "tf.random.set_seed(12) # Équivalent de th.manual_seed(12)\n",
        "\n",
        "# D_keras est la dimension d'embedding définie précédemment (e.g., 4)\n",
        "# sumOfEmbs_keras est le vecteur sommé des embeddings, de forme (D_keras,)\n",
        "\n",
        "# Crée la couche Dense (équivalent de nn.Linear) avec une activation sigmoïde\n",
        "# On peut définir l'activation directement dans la couche Dense pour simplifier\n",
        "W_keras = keras.layers.Dense(units=1, activation='sigmoid', input_shape=(D_keras,))\n",
        "\n",
        "# Pour le passage avant, Keras s'attend à une entrée batchée, même pour un seul exemple.\n",
        "# sumOfEmbs_keras est de forme (D_keras,), nous devons ajouter une dimension de batch.\n",
        "sumOfEmbs_keras_batched = tf.expand_dims(sumOfEmbs_keras, axis=0) # forme (1, D_keras)\n",
        "\n",
        "# Effectuer le passage avant (forward pass)\n",
        "out_keras = W_keras(sumOfEmbs_keras_batched)\n",
        "\n",
        "# La sortie sera de forme (1, 1), car nous avons une dimension de batch de 1 et 1 unité de sortie.\n",
        "# Pour comparer au PyTorch qui était (1,), on peut squeeze la dimension du batch.\n",
        "print(out_keras.shape, tf.squeeze(out_keras))\n",
        "\n",
        "# Si vous voulez l'implémentation étape par étape (Dense puis Sigmoid séparément):\n",
        "# W_keras_no_act = keras.layers.Dense(units=1, input_shape=(D_keras,))\n",
        "# out_activation_keras = tf.keras.activations.sigmoid\n",
        "# out_keras_step_by_step = out_activation_keras(W_keras_no_act(sumOfEmbs_keras_batched))\n",
        "# print(out_keras_step_by_step.shape, tf.squeeze(out_keras_step_by_step))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1) tf.Tensor(0.50064105, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7945d992"
      },
      "source": [
        "1.  **Graine aléatoire** :\n",
        "    *   PyTorch : `th.manual_seed(12)`\n",
        "    *   Keras/TensorFlow : `tf.random.set_seed(12)`. Il est important de la définir pour s'assurer que l'initialisation des poids de la couche `Dense` est reproductible.\n",
        "\n",
        "2.  **Couche Linéaire (Dense)** :\n",
        "    *   PyTorch : `th.nn.Linear(in_features=D, out_features=1)`.\n",
        "    *   Keras : `keras.layers.Dense(units=1, input_shape=(D_keras,))`. Le paramètre `units` est équivalent à `out_features`, et `input_shape` est souvent requis (ou déduit lors du premier appel) pour définir la forme d'entrée attendue. `in_features` est implicitement défini par `input_shape`.\n",
        "\n",
        "3.  **Fonction d'Activation Sigmoïde** :\n",
        "    *   PyTorch : `th.nn.Sigmoid()` appliquée séparément, comme `out_activation(W(sumOfEmbs))`. Les fonctions d'activation peuvent être des couches (`nn.Sigmoid`) ou des fonctions (`F.sigmoid`).\n",
        "    *   Keras : Vous pouvez intégrer l'activation directement dans la couche `Dense` avec l'argument `activation='sigmoid'`, ce qui est la pratique courante et plus concise (`keras.layers.Dense(..., activation='sigmoid')`). Alternativement, vous pourriez appliquer `tf.keras.activations.sigmoid` après la couche `Dense` comme une fonction séparée.\n",
        "\n",
        "4.  **Gestion des dimensions (batch)** :\n",
        "    *   PyTorch : Pour un seul exemple, si `sumOfEmbs` est de forme `(D,)`, `W(sumOfEmbs)` fonctionne souvent directement et produit `(1,)`.\n",
        "    *   Keras : Les couches Keras s'attendent presque toujours à une entrée `batchée`. Si `sumOfEmbs_keras` est de forme `(D_keras,)`, il faut ajouter une dimension de batch (`tf.expand_dims(sumOfEmbs_keras, axis=0)` pour obtenir `(1, D_keras)`). La sortie sera alors de forme `(1, 1)`. Pour une comparaison directe avec la sortie PyTorch `(1,)`, `tf.squeeze` est utilisé pour retirer la dimension de batch de taille 1.\n",
        "\n",
        "En résumé, les concepts sont les mêmes mais la syntaxe et la gestion des dimensions (batching) diffèrent notablement entre les deux frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99631688"
      },
      "source": [
        "Ce segment de code finalise la construction de la prédiction du modèle en prenant la représentation de la phrase (le vecteur d'embeddings sommé) et en la transformant en une probabilité de classification.\n",
        "\n",
        "*   **`W_keras = keras.layers.Dense(units=1, activation='sigmoid', input_shape=(D_keras,))`**\n",
        "    *   **Action**: Cette ligne définit la couche de sortie du modèle.\n",
        "    *   **`keras.layers.Dense`**: C'est la couche entièrement connectée de Keras, équivalente à `nn.Linear` en PyTorch. Elle effectue une transformation linéaire sur ses entrées.\n",
        "    *   **`units=1`**: Indique que cette couche produira une seule valeur en sortie. Pour notre tâche de classification binaire (positive ou négative), cette unique valeur représente la probabilité d'appartenir à la classe positive.\n",
        "    *   **`activation='sigmoid'`**: Applique la fonction d'activation sigmoïde à la sortie de la transformation linéaire. La sigmoïde 'écrase' n'importe quelle valeur réelle entre 0 et 1, ce qui permet d'interpréter la sortie directement comme une probabilité.\n",
        "    *   **`input_shape=(D_keras,)`**: Spécifie la forme attendue pour l'entrée de cette couche. `D_keras` est la dimension des embeddings (par exemple, 4). Cela signifie que la couche `Dense` attend un vecteur de `D_keras` éléments par exemple.\n",
        "\n",
        "*   **`sumOfEmbs_keras_batched = tf.expand_dims(sumOfEmbs_keras, axis=0)`**\n",
        "    *   **Action**: Prépare l'entrée `sumOfEmbs_keras` pour être traitée par la couche `Dense`, en ajoutant une dimension de batch.\n",
        "    *   **Contexte Keras**: Les modèles Keras sont conçus pour travailler avec des *batchs* (lots) de données. Même lorsque vous ne traitez qu'un seul exemple (comme c'est le cas ici pour `sumOfEmbs_keras`), Keras s'attend à ce que l'entrée ait une dimension pour le batch.\n",
        "    *   **Transformation**: Si `sumOfEmbs_keras` a une forme `(D_keras,)` (par exemple, `(4,)`), `tf.expand_dims(..., axis=0)` le transforme en `(1, D_keras)` (par exemple, `(1, 4)`). Le `1` représente la taille du batch (un seul exemple), et `D_keras` est la dimension de la caractéristique de cet exemple.\n",
        "\n",
        "*   **`out_keras = W_keras(sumOfEmbs_keras_batched)`**\n",
        "    *   **Action**: Exécute le passage avant (forward pass) à travers la couche de sortie que nous avons définie.\n",
        "    *   **Déroulement**: La `couche W_keras` prend `sumOfEmbs_keras_batched` (notre vecteur de phrase batché) comme entrée. Elle calcule d'abord le produit matriciel des entrées avec ses poids internes, ajoute son biais, puis applique la fonction sigmoïde. Le résultat, `out_keras`, est un tenseur contenant la probabilité prédite par le modèle.\n",
        "\n",
        "*   **`print(out_keras.shape, tf.squeeze(out_keras))`**\n",
        "    *   **Action**: Affiche la forme du tenseur de sortie et sa valeur réelle après avoir supprimé les dimensions superflues.\n",
        "    *   **`out_keras.shape`**: La sortie directe de `W_keras` aura une forme `(1, 1)`. Le premier `1` est la dimension de batch que nous avons ajoutée, et le second `1` est dû au fait que `units=1` dans la couche `Dense`.\n",
        "    *   **`tf.squeeze(out_keras)`**: Cette fonction est utilisée pour supprimer toutes les dimensions de taille 1 du tenseur. Dans ce cas, elle transforme le tenseur de forme `(1, 1)` en un tenseur scalaire (ou de forme `()` si c'est une valeur unique) ou `(1,)`, ce qui permet d'obtenir la valeur de probabilité unique de manière plus concise et comparable à la sortie de PyTorch pour un seul exemple.\n",
        "\n",
        "En somme, ces étapes traduisent la représentation vectorielle d'une phrase en une unique probabilité binaire, indiquant la prédiction du modèle quant à la classe de la revue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIOT0Mm3pySW"
      },
      "source": [
        "### Encapsuler le tout dans un module\n",
        "\n",
        "Pour écrire votre propre module, héritez de la classe *Module*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLWaKdIEpySX"
      },
      "outputs": [],
      "source": [
        "# pytorch\n",
        "\n",
        "class CBOW_classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW_classifier, self).__init__()\n",
        "        self.emb = nn.Embedding( # crée la couche d'embedding\n",
        "            vocab_size, embedding_dim) # Cette couche prendra des indices de mots en entrée et retournera leurs vecteurs d'embedding correspondants\n",
        "        self.lin = nn.Linear( # crée la couche linéaire\n",
        "            embedding_dim, 1)\n",
        "\n",
        "    def forward( # comment une entrée (inp) est transformée pour produire la sortie du modèle\n",
        "        self, inp):\n",
        "        return th.sigmoid(\n",
        "            self.lin(\n",
        "                self.emb( # convertit chaque indice de mot en son vecteur d'embedding\n",
        "                    inp).sum(\n",
        "                        dim=0)))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dfd2ba3"
      },
      "source": [
        "# keras\n",
        "\n",
        "class CBOW_classifier_keras(keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW_classifier_keras, self).__init__()\n",
        "        # Crée la couche d'embedding\n",
        "        # input_dim correspond à vocab_size, output_dim à embedding_dim\n",
        "        self.emb = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "        # Crée la couche linéaire (Dense)\n",
        "        # units correspond à la taille de sortie (ici 1 pour classification binaire)\n",
        "        self.lin = layers.Dense(units=1)\n",
        "\n",
        "    def call(self, inputs): # La méthode 'call' est l'équivalent de 'forward' en PyTorch\n",
        "        # inputs aura la forme (batch_size, sequence_length)\n",
        "\n",
        "        # 1. Convertit chaque indice de mot en son vecteur d'embedding\n",
        "        # embeddings aura la forme (batch_size, sequence_length, embedding_dim)\n",
        "        embeddings = self.emb(inputs)\n",
        "\n",
        "        # 2. Somme les embeddings le long de la dimension de la séquence (axis=1)\n",
        "        # Cela crée un vecteur de taille (batch_size, embedding_dim) pour chaque exemple\n",
        "        sum_of_embs = tf.reduce_sum(embeddings, axis=1)\n",
        "\n",
        "        # 3. Passe la représentation fixe de la phrase à la couche linéaire\n",
        "        linear_output = self.lin(sum_of_embs)\n",
        "\n",
        "        # 4. Applique l'activation sigmoïde pour obtenir une probabilité entre 0 et 1\n",
        "        return tf.sigmoid(linear_output)\n",
        "\n",
        "# Exemple d'utilisation (pour tester le forward pass)\n",
        "# tf.random.set_seed(1) # Pour la reproductibilité, déjà fait en début de notebook\n",
        "# D_keras = 10 # Utilisons la même dimension d'embedding que l'exemple PyTorch\n",
        "\n",
        "# classifier_keras = CBOW_classifier_keras(vocab_size=VOCAB_SIZE_KERAS, embedding_dim=D_keras)\n",
        "\n",
        "# # Keras attend des entrées batchées, même pour un seul exemple\n",
        "# # texts_for_keras[0] est de forme (sequence_length,)\n",
        "# single_input_batch = tf.expand_dims(texts_for_keras[0], axis=0) # Forme (1, sequence_length)\n",
        "\n",
        "# print(\"Prédiction Keras pour le premier exemple :\", classifier_keras(single_input_batch))\n",
        "# print(\"Vrai label Keras pour le premier exemple :\", labels_for_keras[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1ba98e"
      },
      "source": [
        "1.  **Héritage de la Classe** :\n",
        "    *   PyTorch : Votre modèle hérite de `th.nn.Module`.\n",
        "    *   Keras : Votre modèle hérite de `tf.keras.Model` pour des modèles plus complexes ou de `tf.keras.Sequential` pour des modèles séquentiels simples. `tf.keras.Model` est préférable ici pour définir des couches et un `call` personnalisé.\n",
        "\n",
        "2.  **Constructeur (`__init__`)** :\n",
        "    *   PyTorch : Les couches sont définies comme `self.emb = nn.Embedding(...)` et `self.lin = nn.Linear(...)`.\n",
        "    *   Keras : Les couches sont définies de manière similaire : `self.emb = layers.Embedding(...)` et `self.lin = layers.Dense(...)`. Les paramètres `input_dim`/`output_dim` pour `Embedding` et `units` pour `Dense` sont les équivalents de `num_embeddings`/`embedding_dim` et de la taille de sortie de `nn.Linear`.\n",
        "\n",
        "3.  **Passage Avant (`forward` vs `call`)** : Quand vous faites classifier_keras(single_input_batch), c'est la méthode __call__ de la classe tf.keras.Model qui est exécutée.\n",
        "Cette méthode __call__ s'attend à trouver et à exécuter votre méthode call() pour définir le flux de données à travers votre modèle. Si vous la renommez, Keras ne saura pas comment exécuter votre logique de calcul.\n",
        "    *   PyTorch : La logique de passage avant est implémentée dans la méthode `forward(self, inp)`.\n",
        "    *   Keras : La logique de passage avant est implémentée dans la méthode `call(self, inputs)`. C'est là que le flux de données à travers les couches est défini.\n",
        "\n",
        "4.  **Gestion des Entrées (Batching)** :\n",
        "    *   PyTorch : Le `forward` est souvent flexible et peut accepter un seul exemple ou un batch. Si `inp` est de forme `(sequence_length,)`, `emb(inp)` retourne `(sequence_length, embedding_dim)`. La somme est alors `sum(dim=0)`.\n",
        "    *   Keras : La méthode `call` de `tf.keras.Model` s'attend *toujours* à des entrées batchées. Donc, `inputs` aura la forme `(batch_size, sequence_length)`. Après l'embedding, `embeddings` aura la forme `(batch_size, sequence_length, embedding_dim)`.\n",
        "    *   Pour sommer les embeddings de mots dans chaque séquence (pour chaque élément du batch), nous utilisons `tf.reduce_sum(embeddings, axis=1)`. Notez que l'`axis` est `1` ici car l'axe `0` est la dimension du batch et l'axe `1` est la dimension de la séquence. Le résultat sera de forme `(batch_size, embedding_dim)`.\n",
        "\n",
        "5.  **Fonction d'Activation** :\n",
        "    *   PyTorch : `th.sigmoid(...)` est appliqué à la sortie de la couche linéaire.\n",
        "    *   Keras : `tf.sigmoid(...)` est l'équivalent. Vous pouvez aussi l'intégrer directement dans la couche `Dense` comme `layers.Dense(units=1, activation='sigmoid')` pour un code plus concis (ce que j'ai fait dans l'exemple étape par étape précédent).\n",
        "\n",
        "En résumé, les concepts de couches d'embedding, couches linéaires et fonctions d'activation sont les mêmes, mais la syntaxe de leur définition et surtout la manière de gérer le flux de données (particulièrement l'attente d'entrées batchées et la spécification des axes pour les opérations) diffèrent entre PyTorch et Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "cs5wXpWwpySX"
      },
      "source": [
        "Cette classe hérite de *Module*. Ces deux méthodes sont obligatoires. Le constructeur construit un modèle avec ses paramètres initialisés. Le *forward* est pour l'inférence.\n",
        "\n",
        "Le tenseur d'embeddings résultant de l'étape précédente (qui a la forme [nombre_de_mots, embedding_dim]) est ensuite sommé le long de la dimension 0 (la dimension des mots). Cela produit un seul vecteur de taille embedding_dim, qui représente la phrase entière (le principe du Bag of Words).\n",
        "\n",
        "Dans PyTorch, un modèle prend des *Tensors (variables)* en entrée et renvoie des *Tensors (variables)*. La sortie est comparée à la vérité terrain par la fonction de perte.\n",
        "\n",
        "Prenons un exemple d'entraînement et vérifions si le passage avant (forward pass) est correct. Le résultat devrait être un *FloatTensor* avec une seule valeur : le score entre 0 et 1 attribué par le modèle à l'exemple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIlrnlyMpySX",
        "outputId": "9fd6769d-002a-4cad-875e-ffef4b306831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6236], grad_fn=<SigmoidBackward>)\n",
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "#pytorch\n",
        "\n",
        "classifier = CBOW_classifier(\n",
        "    vocab_size=len(\n",
        "        lexicon),embedding_dim=10) # hyperparamètre important que vous pourrez ajuster\n",
        "print(classifier(texts[0]))\n",
        "print(labels[0]) # vrai label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette valeur est la prédiction du modèle pour le texte texts[0], représentant la probabilité que ce texte soit une critique positive. Une valeur proche de 1 indique une forte probabilité d'être positif, et une valeur proche de 0 indique une forte probabilité d'être négatif."
      ],
      "metadata": {
        "id": "iMOo9Uqu_T22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFWSldy6pySY",
        "outputId": "bb7b2097-d081-4f63-b030-ffa7884b8395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6236], grad_fn=<SigmoidBackward>)\n"
          ]
        }
      ],
      "source": [
        "# PYTORCH\n",
        "\n",
        "print(classifier.forward(texts[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "classifier(texts[0]) est une syntaxe raccourcie et préférée pour classifier.forward(texts[0]) dans PyTorch"
      ],
      "metadata": {
        "id": "uw1sVYrI_9K9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ef3e1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05475dcc-7950-4bde-d803-cc428a978184"
      },
      "source": [
        "# Créer une instance du classificateur CBOW pour Keras\n",
        "\n",
        "# Nous utilisons VOCAB_SIZE_KERAS et une dimension d'embedding de 10, comme dans l'exemple PyTorch.\n",
        "D_keras_model = 10 # Dimension de l'embedding pour le modèle\n",
        "classifier_keras = CBOW_classifier_keras(\n",
        "    vocab_size=VOCAB_SIZE_KERAS,\n",
        "    embedding_dim=D_keras_model)\n",
        "\n",
        "# Obtenir une entrée unique pour la prédiction (ici, le premier texte)\n",
        "# Keras attend des entrées batchées, même pour un seul exemple.\n",
        "# texts_for_keras[0] est de forme (sequence_length,)\n",
        "single_input_batch = tf.expand_dims(texts_for_keras[0], axis=0) # Convertir en forme (1, sequence_length)\n",
        "\n",
        "# Obtenir la prédiction du modèle Keras\n",
        "keras_prediction = classifier_keras(single_input_batch)\n",
        "\n",
        "# Afficher la prédiction et le vrai label\n",
        "# La prédiction Keras sera de forme (1, 1), donc nous utilisons tf.squeeze pour obtenir un scalaire.\n",
        "print(\"Prédiction Keras pour texts_for_keras[0]:\", tf.squeeze(keras_prediction))\n",
        "print(\"Vrai label pour labels_for_keras[0]:\", labels_for_keras[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction Keras pour texts_for_keras[0]: tf.Tensor(0.48061645, shape=(), dtype=float32)\n",
            "Vrai label pour labels_for_keras[0]: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "125c88dc"
      },
      "source": [
        "1.  **Instantiation du modèle** :\n",
        "    *   PyTorch : `classifier = CBOW_classifier(vocab_size=len(lexicon), embedding_dim=10)`\n",
        "    *   Keras : `classifier_keras = CBOW_classifier_keras(vocab_size=VOCAB_SIZE_KERAS, embedding_dim=D_keras_model)`\n",
        "    *   Le principe est le même : instancier la classe du modèle avec la taille du vocabulaire et la dimension d'embedding. Nous utilisons `VOCAB_SIZE_KERAS` et avons défini une variable `D_keras_model` pour la dimension d'embedding.\n",
        "\n",
        "2.  **Prédiction (appel `forward`/`call`)** :\n",
        "    *   PyTorch : `print(classifier(texts[0]))` appelle implicitement la méthode `forward` de la classe `CBOW_classifier`.\n",
        "    *   Keras : `keras_prediction = classifier_keras(single_input_batch)` appelle implicitement la méthode `call` de la classe `CBOW_classifier_keras`.\n",
        "\n",
        "3.  **Préparation de l'entrée** :\n",
        "    *   **C'est une différence fondamentale**. PyTorch peut souvent gérer un seul exemple (`texts[0]`) directement. Son `forward` est conçu pour traiter des tenseurs non batchés s'il y a lieu.\n",
        "    *   Keras (et TensorFlow en général) est fortement orienté vers le traitement par lots. Ainsi, `texts_for_keras[0]` qui est un tableau NumPy de forme `(longueur_sequence,)` doit être transformé en un batch de taille 1, `(1, longueur_sequence)`, à l'aide de `tf.expand_dims(..., axis=0)`.\n",
        "\n",
        "4.  **Accès au vrai label** :\n",
        "    *   PyTorch : `print(labels[0])` accède à la première valeur du tenseur `labels`.\n",
        "    *   Keras : `print(labels_for_keras[0])` accède à la première valeur du tableau NumPy `labels_for_keras`.\n",
        "\n",
        "5.  **Forme de la sortie** :\n",
        "    *   La sortie du modèle PyTorch (`classifier(texts[0])`) était un tenseur scalaire `tensor([0.6236])` (forme `(1,)`).\n",
        "    *   La sortie du modèle Keras (`keras_prediction`) sera un tenseur de forme `(1, 1)` (batch de 1, 1 unité de sortie). Pour obtenir une valeur scalaire pour la comparaison ou l'affichage, nous utilisons `tf.squeeze(keras_prediction)` qui supprime les dimensions de taille 1.\n",
        "\n",
        "En résumé, les concepts sont les mêmes, mais la gestion explicite des batchs est une étape cruciale en Keras pour le passage avant d'un modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEqE-4ippySY"
      },
      "source": [
        "### Fonction objectif\n",
        "La fonction de perte (ou fonction objectif) est adaptée au modèle et à la tâche.\n",
        "\n",
        "- Lisez la documentation du module **nn** : http://pytorch.org/docs/master/nn.html.\n",
        "- Dans notre cas, deux fonctions de perte peuvent être utilisées : *BCELoss* et *BCEWithLogitsLoss*. Comparez-les et faites votre choix.\n",
        "- Compte tenu de ce choix, vous pourriez vouloir modifier la classe *CBOW_Classifier*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOg8oBhTpySY"
      },
      "outputs": [],
      "source": [
        "# pytorch\n",
        "\n",
        "## define de training function\n",
        "loss_fn = nn.BCELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab9c10f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef1b010-ec24-439d-814f-e3ad16b5db66"
      },
      "source": [
        "# keras\n",
        "\n",
        "# Définition de la fonction de perte pour Keras\n",
        "# BinaryCrossentropy est l'équivalent direct de BCELoss pour la classification binaire.\n",
        "loss_fn_keras = keras.losses.BinaryCrossentropy()\n",
        "\n",
        "print(\"Fonction de perte Keras définie:\", loss_fn_keras)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fonction de perte Keras définie: <LossFunctionWrapper(<function binary_crossentropy at 0x7f399aa89120>, kwargs={'from_logits': False, 'label_smoothing': 0.0, 'axis': -1})>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6928d0bf"
      },
      "source": [
        "**Fonction de Perte** :\n",
        "\n",
        "    *   PyTorch : `nn.BCELoss()` est la Binary Cross-Entropy Loss, utilisée pour la classification binaire lorsque la sortie du modèle est déjà une probabilité (entre 0 et 1, généralement après une activation Sigmoid).\n",
        "    *   Keras : `keras.losses.BinaryCrossentropy()` est l'équivalent direct. Elle attend également des probabilités en entrée du modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pDdDsFBmpySZ"
      },
      "source": [
        "### Entraînement\n",
        "\n",
        "Écrivons le code pour entraîner le modèle, surveiller le processus d'entraînement et évaluer le modèle à l'aide des données de test. Commençons avec un optimiseur SGD avec un taux d'apprentissage de 0,1.\n",
        "\n",
        "### Ordre aléatoire\n",
        "Dans de nombreux cas, il peut être important d'itérer sur les données dans un ordre aléatoire et non dans l'ordre dans lequel nous avons construit le corpus. Cet ordre initial peut introduire un biais dans le processus d'évaluation. Une méthode simple pour mélanger les données est de mélanger les indices que nous utilisons. Supposons que nous ayons 10 échantillons d'entraînement, nous pouvons faire quelque chose comme :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yPZ4J8ypySZ",
        "outputId": "207db18a-a6c1-461d-d9f3-508e0e18256d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "0\n",
            "2\n",
            "3\n",
            "8\n",
            "7\n",
            "9\n",
            "6\n",
            "1\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "# pytorch\n",
        "\n",
        "ids = list(range(10))\n",
        "import random\n",
        "random.shuffle(ids)\n",
        "for i in ids:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est une technique courante en apprentissage automatique pour s'assurer que les données sont traitées dans un ordre non séquentiel, ce qui aide à éviter les biais et à améliorer la généralisation du modèle pendant l'entraînement."
      ],
      "metadata": {
        "id": "joNphzvbBJjd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkLbvcefpySZ"
      },
      "source": [
        "##### Maintenant, nous avons tout pour exécuter la boucle d'entraînement et tester ce modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FN8eCwkpySa",
        "outputId": "a7be379c-0a06-408e-c669-c3cb0efd7906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(0.7279) 54.54333333333334 tensor(15049.)\n",
            "1 tensor(0.6946) 58.906666666666666 tensor(15068.)\n",
            "2 tensor(0.6643) 62.86333333333334 tensor(14997.)\n",
            "3 tensor(0.6356) 65.49333333333334 tensor(15064.)\n",
            "4 tensor(0.6110) 67.36 tensor(14950.)\n",
            "5 tensor(0.5916) 68.86666666666666 tensor(14988.)\n",
            "6 tensor(0.5753) 69.91333333333333 tensor(14934.)\n",
            "7 tensor(0.5615) 71.37 tensor(14945.)\n",
            "8 tensor(0.5477) 72.33666666666667 tensor(14995.)\n",
            "9 tensor(0.5371) 72.68 tensor(14916.)\n"
          ]
        }
      ],
      "source": [
        "# pytorch\n",
        "\n",
        "total = len(texts)\n",
        "randomidx = list(range(total))\n",
        "preds = th.zeros(\n",
        "    total) # sera utilisé pour stocker les prédictions du modèle pour chaque exemple à la fin de chaque époque.\n",
        "optimizer = th.optim.SGD(\n",
        "    classifier.parameters(\n",
        "\n",
        "    ),lr=1e-2) # détermine la taille des pas effectués lors de la mise à jour des poids\n",
        "Nepochs = 10\n",
        "losses = th.zeros(\n",
        "    Nepochs) # Initialise un tenseur pour stocker la perte moyenne de chaque époque\n",
        "for epoch in range(Nepochs):\n",
        "    total_loss = th.Tensor(\n",
        "        [0]) # Réinitialise la perte totale accumulée pour l'époque courante à 0\n",
        "    correct=0 # Réinitialise le compteur de prédictions correctes pour l'époque courante à 0\n",
        "    random.shuffle(\n",
        "        randomidx) # éviter l'apprentissage de motifs liés à l'ordre des données plutôt qu'aux données elles-mêmes\n",
        "    for i in randomidx:\n",
        "        classifier.zero_grad(\n",
        "\n",
        "        )\n",
        "        x = texts[\n",
        "            i] # Récupère le texte (séquence d'indices de mots) pour l'exemple courant\n",
        "        probs = classifier(\n",
        "            x)[0] # extraire la seule valeur scalaire de probabilité du tenseur de sortie\n",
        "        loss = loss_fn(\n",
        "            probs, labels[\n",
        "                i]) # perte (erreur) entre la probabilité prédite et le vrai label\n",
        "        pred= probs>0.5\n",
        "        preds[i] = pred\n",
        "        if pred.item(\n",
        "\n",
        "        ) == labels[ # Vérifie si la prédiction correspond au vrai label\n",
        "            i].item() :\n",
        "            correct +=1\n",
        "        loss.backward(\n",
        "\n",
        "        ) # calcule les gradients de la fonction de perte par rapport à tous les paramètres du modèle\n",
        "        optimizer.step(\n",
        "\n",
        "        ) # Met à jour les poids du modèle\n",
        "        total_loss += loss.data\n",
        "    losses[epoch] = total_loss/total # perte moyenne pour l'époque\n",
        "    print(epoch, losses[epoch], 100.0*correct/total, preds.sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quatrième colonne (ex: tensor(15049.) à tensor(14916.)) : C'est le nombre total de prédictions positives faites par le modèle sur l'ensemble des données d'entraînement pour cette époque. Étant donné que le jeu de données contient 30 000 exemples (15 000 positifs et 15 000 négatifs, comme mentionné dans la description initiale), ce nombre indique comment le modèle répartit ses prédictions entre les deux classes. Les valeurs sont autour de 15 000, ce qui suggère que le modèle ne penche pas excessivement vers une classe ou l'autre, et que la distribution des prédictions positives et négatives est relativement équilibrée."
      ],
      "metadata": {
        "id": "CUwc-6vMisio"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe55a9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f679e82f-5ac0-4a32-fff2-92af757cc555"
      },
      "source": [
        "# keras\n",
        "\n",
        "# S'assurer que le classificateur Keras et les données sont disponibles\n",
        "# VOCAB_SIZE_KERAS, D_keras_model, texts_for_keras, labels_for_keras doivent être définis\n",
        "\n",
        "# Recréer le classificateur Keras avec la dimension d'embedding souhaitée\n",
        "D_keras_model = 10\n",
        "classifier_keras = CBOW_classifier_keras(\n",
        "    vocab_size=VOCAB_SIZE_KERAS,\n",
        "    embedding_dim=D_keras_model)\n",
        "\n",
        "# 1. Préparer les données pour Keras\n",
        "# Nous allons les convertir en tf.data.Dataset pour un traitement par lots efficace\n",
        "# Keras/TF préfère les tenseurs TF pour l'entraînement\n",
        "texts_tf = [tf.constant(t, dtype=tf.int32) for t in texts_for_keras]\n",
        "labels_tf = tf.constant(labels_for_keras, dtype=tf.float32)\n",
        "\n",
        "# La perte est de type BinaryCrossentropy (déjà définie comme loss_fn_keras)\n",
        "# Créer un optimiseur SGD pour Keras\n",
        "optimizer_keras = optimizers.SGD(learning_rate=1e-2)\n",
        "\n",
        "Nepochs = 10\n",
        "losses_keras_per_epoch = []\n",
        "accuracies_keras_per_epoch = []\n",
        "\n",
        "total_samples = len(texts_tf)\n",
        "\n",
        "print(\"--- Entraînement du modèle Keras ---\")\n",
        "for epoch in range(Nepochs):\n",
        "    total_loss_epoch = 0.0\n",
        "    correct_predictions = 0\n",
        "    predictions_epoch = np.zeros(total_samples) # Pour stocker les prédictions\n",
        "\n",
        "    # Mélanger les indices pour chaque époque\n",
        "    random_indices = list(range(total_samples))\n",
        "    random.shuffle(random_indices)\n",
        "\n",
        "    for i_idx, i in enumerate(random_indices):\n",
        "        # Récupère le texte et le label pour l'exemple courant\n",
        "        x_single = texts_tf[i]\n",
        "        y_true_single = labels_tf[i]\n",
        "\n",
        "        # Keras attend des entrées batchées, même pour un seul exemple\n",
        "        x_batch = tf.expand_dims(x_single, axis=0)\n",
        "        y_true_batch = tf.expand_dims(y_true_single, axis=0)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Passage avant (forward pass)\n",
        "            y_pred_batch = classifier_keras(x_batch, training=True)\n",
        "            # Calcul de la perte\n",
        "            loss_value = loss_fn_keras(y_true_batch, y_pred_batch)\n",
        "\n",
        "        # Calcul des gradients\n",
        "        grads = tape.gradient(loss_value, classifier_keras.trainable_variables)\n",
        "\n",
        "        # Appliquer les gradients pour mettre à jour les poids\n",
        "        optimizer_keras.apply_gradients(zip(grads, classifier_keras.trainable_variables))\n",
        "\n",
        "        # Accumuler la perte\n",
        "        total_loss_epoch += loss_value.numpy()\n",
        "\n",
        "        # Calculer la précision\n",
        "        # Pour la prédiction, tf.round(y_pred_batch) convertit les probabilités en 0 ou 1\n",
        "        predicted_class = tf.round(y_pred_batch)\n",
        "        if predicted_class.numpy().item() == y_true_single.numpy().item():\n",
        "            correct_predictions += 1\n",
        "        predictions_epoch[i] = predicted_class.numpy().item()\n",
        "\n",
        "    avg_loss_epoch = total_loss_epoch / total_samples\n",
        "    accuracy_epoch = 100.0 * correct_predictions / total_samples\n",
        "\n",
        "    losses_keras_per_epoch.append(avg_loss_epoch)\n",
        "    accuracies_keras_per_epoch.append(accuracy_epoch)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{Nepochs}, Loss: {avg_loss_epoch:.4f}, Accuracy: {accuracy_epoch:.2f}%, Total Pos Preds: {np.sum(predictions_epoch)}\")\n",
        "\n",
        "# Convertir la liste des pertes en tenseur TF pour l'affichage (similaire à PyTorch)\n",
        "losses_keras_tf = tf.constant(losses_keras_per_epoch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Entraînement du modèle Keras ---\n",
            "Epoch 1/10, Loss: 0.5024, Accuracy: 75.57%, Total Pos Preds: 14988.0\n",
            "Epoch 2/10, Loss: 0.4199, Accuracy: 80.79%, Total Pos Preds: 14829.0\n",
            "Epoch 3/10, Loss: 0.3942, Accuracy: 82.40%, Total Pos Preds: 14836.0\n",
            "Epoch 4/10, Loss: 0.3775, Accuracy: 83.12%, Total Pos Preds: 14803.0\n",
            "Epoch 5/10, Loss: 0.3672, Accuracy: 83.74%, Total Pos Preds: 14887.0\n",
            "Epoch 6/10, Loss: 0.3611, Accuracy: 84.02%, Total Pos Preds: 14830.0\n",
            "Epoch 7/10, Loss: 0.3528, Accuracy: 84.50%, Total Pos Preds: 14807.0\n",
            "Epoch 8/10, Loss: 0.3480, Accuracy: 84.76%, Total Pos Preds: 14747.0\n",
            "Epoch 9/10, Loss: 0.3452, Accuracy: 84.82%, Total Pos Preds: 14805.0\n",
            "Epoch 10/10, Loss: 0.3393, Accuracy: 85.06%, Total Pos Preds: 14811.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51a6ffee"
      },
      "source": [
        "1.  **Variables Générales** :\n",
        "    *   `total`, `Nepochs`, `randomidx` (maintenant `random_indices`) fonctionnent de manière similaire. `preds` est remplacé par `predictions_epoch` pour Keras.\n",
        "\n",
        "2.  **Données Keras (`texts_tf`, `labels_tf`)** :\n",
        "    *   `texts_for_keras` et `labels_for_keras` sont des tableaux NumPy (après nos conversions précédentes). Pour une intégration optimale avec Keras et TensorFlow, il est souvent préférable de les convertir en `tf.Tensor` pour l'entraînement. C'est pourquoi nous avons `texts_tf` et `labels_tf`.\n",
        "\n",
        "3.  **Optimiseur** :\n",
        "    *   PyTorch : `th.optim.SGD(classifier.parameters(), lr=1e-2)`.\n",
        "    *   Keras : `optimizer_keras = optimizers.SGD(learning_rate=1e-2)`. L'optimiseur est instancié séparément, et ses paramètres ne sont pas liés au modèle dès la création. Il sera lié lors de `apply_gradients`.\n",
        "\n",
        "4.  **Boucle d'entraînement** :\n",
        "    *   La structure générale (boucle sur les époques, puis mélange des indices, puis boucle sur les exemples) est conservée pour la comparaison.\n",
        "\n",
        "5.  **Passage Avant (Forward Pass) et Perte** :\n",
        "    *   PyTorch : `probs = classifier(x)[0]`, `loss = loss_fn(probs, labels[i])`.\n",
        "    *   Keras : `y_pred_batch = classifier_keras(x_batch, training=True)` (notez `training=True` pour s'assurer que les couches comme Dropout se comportent correctement si elles étaient présentes). La perte est calculée avec `loss_value = loss_fn_keras(y_true_batch, y_pred_batch)`.\n",
        "\n",
        "6.  **Gestion des Gradients (`tf.GradientTape`)** :\n",
        "    *   PyTorch : `classifier.zero_grad()`, `loss.backward()`, `optimizer.step()`.\n",
        "    *   Keras (dans une boucle personnalisée) : C'est la plus grande différence conceptuelle.\n",
        "        *   `with tf.GradientTape() as tape:` : `GradientTape` enregistre toutes les opérations effectuées sur les variables 'regardées' pour calculer les gradients par la suite. Toutes les variables d'un modèle Keras sont automatiquement 'regardées' si elles sont entraînables.\n",
        "        *   `grads = tape.gradient(loss_value, classifier_keras.trainable_variables)` : Calcule les gradients de la perte par rapport à toutes les variables entraînables du modèle.\n",
        "        *   `optimizer_keras.apply_gradients(zip(grads, classifier_keras.trainable_variables))` : Applique les gradients calculés pour mettre à jour les poids du modèle. Le `optimizer.zero_grad()` de PyTorch est géré implicitement par Keras/TensorFlow dans ce processus.\n",
        "\n",
        "7.  **Batching** :\n",
        "    *   **Crucial pour Keras** : Contrairement à PyTorch qui peut parfois gérer des entrées non batchées (un seul exemple), Keras attend presque toujours des entrées batchées. C'est pourquoi nous utilisons `tf.expand_dims(x_single, axis=0)` pour transformer un seul exemple en un batch de taille 1 (`(1, sequence_length)`).\n",
        "\n",
        "8.  **Calcul de la Précision** :\n",
        "    *   Le principe est le même : comparer la prédiction binaire (probabilité > 0.5) au vrai label. La conversion `.numpy().item()` est utilisée pour extraire la valeur scalaire des tenseurs TensorFlow pour la comparaison Python.\n",
        "\n",
        "En résumé, Keras gère la différenciation automatique avec `tf.GradientTape` et l'application des gradients via l'optimiseur. Il met un fort accent sur les opérations batchées, ce qui nécessite une préparation des données et des ajustements dans la boucle d'entraînement par rapport à une approche PyTorch unitaire."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   epoch : Le numéro de l'époque.\n",
        "*   losses[epoch] : La perte moyenne de l'époque.\n",
        "*   100.0*correct/total : L'exactitude (accuracy) du modèle sur l'ensemble du jeu de données pour cette époque (en pourcentage).\n",
        "*   preds.sum() : Le nombre total de prédictions positives faites par le modèle sur l'ensemble du jeu de données. Cela peut donner une idée du biais du modèle (s'il prédit trop souvent positif ou négatif)."
      ],
      "metadata": {
        "id": "SugUaQPGHJ3_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvduf49XpySa",
        "outputId": "1435f946-064f-47ef-c8f8-f1fc951d87ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f57963942d0>]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#pytorch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06e6f1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "38b526e9-ffc6-4a47-eb2c-67f9498817e7"
      },
      "source": [
        "# keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# La variable 'losses_keras_per_epoch' a été remplie par la boucle d'entraînement Keras.\n",
        "# Elle est une liste de flottants.\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(losses_keras_per_epoch, label='Keras Training Loss')\n",
        "plt.title('Evolution de la Perte d\\'/entraînement en Keras')\n",
        "plt.xlabel('Époque')\n",
        "plt.ylabel('Perte Moyenne')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Alternativement, si vous préférez utiliser le tenseur TensorFlow converti :\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# plt.plot(losses_keras_tf.numpy(), label='Keras Training Loss (from tf.Tensor)')\n",
        "# plt.title('Evolution de la Perte d\\'/entraînement en Keras')\n",
        "# plt.xlabel('Époque')\n",
        "# plt.ylabel('Perte Moyenne')\n",
        "# plt.grid(True)\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d6bda77"
      },
      "source": [
        "Même si vous avez défini la même graine aléatoire (`tf.random.set_seed(12)` pour Keras et `th.manual_seed(12)` pour PyTorch), il y a plusieurs raisons pour lesquelles la perte initiale peut différer entre les deux frameworks :\n",
        "\n",
        "*   **Initialisation des poids par défaut** : Bien que les graines aléatoires assurent la reproductibilité *au sein de chaque framework*, les implémentations par défaut des initialiseurs de poids peuvent être différentes entre PyTorch et Keras (TensorFlow). Keras utilise souvent des initialiseurs comme Glorot uniformément pour les poids et des zéros pour les biais par défaut dans ses couches `Dense`, tandis que PyTorch peut avoir ses propres schémas d'initialisation par défaut pour `nn.Linear` et `nn.Embedding`. Ces légères différences dans les valeurs initiales des poids peuvent entraîner des performances de départ différentes.\n",
        "\n",
        "*   **Précision numérique et opérations** : Les opérations de tenseurs, bien que similaires conceptuellement, peuvent avoir de subtiles différences dans leur implémentation sous-jacente ou leur précision numérique entre les deux bibliothèques. Cela peut affecter la façon dont les embeddings sont générés et sommés, puis comment la sortie finale est calculée.\n",
        "\n",
        "*   **Ordre des opérations/dépendances** : Même si les graines sont définies, si d'autres opérations aléatoires sont appelées avant l'initialisation des couches, cela pourrait légèrement perturber la séquence des nombres pseudo-aléatoires utilisés pour les poids spécifiques du modèle. Cependant, dans votre cas, vous avez défini la graine juste avant de créer la couche linéaire, ce qui devrait minimiser cela.\n",
        "\n",
        "En général, une perte initiale plus basse en Keras peut indiquer que son initialisation par défaut des poids a commencé à partir d'un point légèrement plus favorable pour la tâche, ou que les valeurs de ses poids sont plus proches des valeurs optimales.\n",
        "\n",
        "L'important est la **tendance de la perte au fil des époques** et la performance finale du modèle, plutôt que la valeur absolue de la perte initiale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "853f1072"
      },
      "source": [
        "## Premières Expériences\n",
        "\n",
        "*   Effectuer des expériences avec 2000 exemples pour commencer, puis avec toutes les données d'entraînement (réparties équitablement entre les exemples positifs et négatifs).\n",
        "*   Vous devriez créer des ensembles de développement et de test.\n",
        "*   Tester différentes paramétrisations du modèle (ici la taille de l'embedding) et l'hyper-paramètre (le taux d'apprentissage) pour chaque configuration.\n",
        "*   Comparer ces différentes configurations (fonction de perte sur l'entraînement et également la précision de classification).\n",
        "\n",
        "## Un modèle plus profond\n",
        "\n",
        "*   Nous pouvons ajouter une couche cachée au classificateur précédent.\n",
        "*   Faire de même qu'avant avec les différentes configurations.\n",
        "*   Trouver le bon choix d'hyper-paramètres."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}