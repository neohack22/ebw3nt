{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/ebw3nt/blob/main/modelisation/Impl%C3%A9mentationCBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl9nmloVpySE"
      },
      "source": [
        "The goal is to set up a simple classifier for text and sentiment analysis. The task is the binary classification of movie reviews. The dataset is a part of the *imdb* dataset. You can find the original dataset on the [imdb website](https://www.imdb.com/interfaces/) or a version on the [kaggle website](https://www.kaggle.com/utathya/imdb-review-dataset). For this lab session, we will use a preprocessed version.\n",
        "\n",
        "\n",
        "The roadmap is:\n",
        "- Load, clean and setup the data (in practice this a very important step, for this lab we skip it).\n",
        "- Make it suitable for pytorch models\n",
        "- Define your own model\n",
        "- Experiments\n",
        "\n",
        "\n",
        "# The data\n",
        "\n",
        "Datasets are available in the cloud repository. There are 2 files, one for positive reviews (imdb.pos) and one for the negative ones (imdb.neg). There are  300000 examples of each class.\n",
        "\n",
        "Here two functions to load and clean the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aLVRPoUpySK",
        "outputId": "c5a27f1c-3e71-496e-b322-32c359f89ce9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f57a2a39350>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.autograd as ag\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "th.manual_seed(1) # set the seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ucjfrVbpySN"
      },
      "source": [
        "# Data loading\n",
        "\n",
        "\n",
        "Load the data :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K59vHLBpySN",
        "outputId": "745ce76b-1536-4f21-fc3a-b3db55efd4d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-06 11:30:46--  https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.18.206, 2a00:1450:4007:812::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.18.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/n2hk1hevtcvg0o0qrmu5u6kngpg8htco/1649237400000/16692574002775380562/*/1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-06 11:30:50--  https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/n2hk1hevtcvg0o0qrmu5u6kngpg8htco/1649237400000/16692574002775380562/*/1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA?e=download\n",
            "Resolving doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)... 216.58.213.129, 2a00:1450:4007:811::2001\n",
            "Connecting to doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)|216.58.213.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1552309 (1,5M) [application/x-gzip]\n",
            "Saving to: ‘imdb.pck.gz’\n",
            "\n",
            "imdb.pck.gz         100%[===================>]   1,48M  5,08MB/s    in 0,3s    \n",
            "\n",
            "2022-04-06 11:30:51 (5,08 MB/s) - ‘imdb.pck.gz’ saved [1552309/1552309]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# find the file imdb.pck.gz, and set the next variable accordingly\n",
        "filename = 'imdb.pck.gz'\n",
        "\n",
        "# You can download the file with the following line:\n",
        "! wget \"https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\" -O imdb.pck.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "hVFv-0u_pySO"
      },
      "source": [
        "Open the data with python and you will get 3 objects :\n",
        "- *texts*  : a list of tensors, each tensor represent a word sequence to classify.\n",
        "- *labels* : the class, positive or negative, of the corresponding text\n",
        "- *lexicon*: a dictionnary to map integers to real words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlMFMQ08pySO",
        "outputId": "d52cb691-861d-4f36-c49f-269a8c45afed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'> <class 'torch.Tensor'> <class 'dict'>\n",
            "tensor([ 36,  25, 381,  10,  58,  21,  83])\n",
            "nb examples :  30000\n",
            "Vocab size:  5002\n"
          ]
        }
      ],
      "source": [
        "fp = gzip.open(filename,'rb')\n",
        "texts , labels, lexicon  = pickle.load(fp)\n",
        "\n",
        "print(type(texts), type(labels), type(lexicon))\n",
        "print(texts[0])\n",
        "print(\"nb examples : \", len(texts))\n",
        "VOCAB_SIZE = len(lexicon)\n",
        "print(\"Vocab size: \", VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBHrK2okpySP"
      },
      "source": [
        "Note that a reduced number of words are selected to build the vocabulary. The less frequent words are discarded are replaced by a specific form (*unk* for unknown).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SlDfDuVpySQ",
        "outputId": "92b5a3ea-7909-44db-d2ec-4e8b3913cc98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word of index 0  :  <pad>\n",
            "word of index 1  :  <unk>\n",
            "word of index 2  :  !\n",
            "word of index 3  :  the\n",
            "word of index 4  :  a\n",
            "word of index 5  :  of\n",
            "word of index 6  :  movie\n",
            "word of index 7  :  and\n",
            "word of index 8  :  this\n",
            "word of index 9  :  to\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(\"word of index\", i , \" : \", lexicon[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08EvO2IfpySR"
      },
      "source": [
        "To read the text you can use for example the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUNU4tIdpySR",
        "outputId": "26aaa4f1-ed60-496f-f151-baedc638f5b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7])\n",
            "Some positive reviews\n",
            "------------\n",
            "['strong', 'drama']\n",
            "['please', 'remake', 'this', 'movie']\n",
            "['very', 'funny', '!']\n",
            "['great', 'series']\n",
            "['fun', 'movie']\n",
            "Some negative reviews\n",
            "------------\n",
            "['absolute', 'waste', 'of', 'time']\n",
            "['the', 'worst', 'movie', 'ever', 'made']\n",
            "['slow', 'motion', 'picture', 'that', 'did', \"n't\", 'get', 'to', 'the', 'point']\n",
            "['there', 'are', 'good', 'bad', 'movies', 'and', 'there', 'are', 'bad', 'bad', 'movies', 'this', 'one', 'is', 'a', 'real', 'stinker']\n",
            "['<unk>', 'so', 'bad', 'its', 'funny']\n",
            "-----------\n",
            "A random sentence: \n",
            "['you', 'definitely', 'need', 'to', 'see', 'this', 'movie']\n"
          ]
        }
      ],
      "source": [
        "def idx2wordlist(idx_array,lexicon):\n",
        "    l = []\n",
        "    for i in idx_array:\n",
        "        l.append(lexicon[i.item()])\n",
        "    return l\n",
        "print(texts[0].shape)\n",
        "print(\"Some positive reviews\")\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "    print(\n",
        "        idx2wordlist(\n",
        "            texts[\n",
        "                i+50],lexicon)) # les critiques positives sont regroupées dans une certaine partie de la liste texts\n",
        "print(\"Some negative reviews\")\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "    print(\n",
        "        idx2wordlist(\n",
        "            texts[\n",
        "                -i-2000],lexicon)) # les critiques négatives sont stockées à la fin de la liste\n",
        "\n",
        "print(\"-----------\\nA random sentence: \")\n",
        "print(idx2wordlist(texts[104],lexicon))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtlcwqfQpySS"
      },
      "source": [
        "# Interface données/modèle\n",
        "En pratique, nous partons de textes bruts et nous devons les convertir en indices de mots. À cette étape, nous pouvons effectuer un prétraitement du texte, une tokenisation et un nettoyage des données. Dans le cas présent, c'est déjà fait. Mais dans la vie réelle, c'est une étape très importante.\n",
        "\n",
        "L'objectif est d'implémenter un classificateur CBOW (Continuous Bag of Words, ou un sac d'embeddings de mots). Cela signifie que la première couche du modèle gère les embeddings de mots.\n",
        "\n",
        "Le module Embedding de PyTorch est conçu à cet effet. Ce module attend en entrée un tableau ou une liste d'indices de mots. Pour cette session, l'objectif est de développer rapidement un modèle. L'interface de données est donc plutôt simple. Nous terminons cette section en créant des labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f2e94a5"
      },
      "source": [
        "# Un premier modèle\n",
        "\n",
        "Le premier modèle est un CBOW (Continuous Bag of Words). Un texte est représenté comme un ensemble de mots (un sac de caractéristiques binaires) :\n",
        "\n",
        "- Chaque mot est associé à son embedding.\n",
        "- Le texte est représenté comme la somme des embeddings de mots impliqués.\n",
        "- Cette somme d'embeddings est ensuite alimentée à une couche linéaire avec une unité de sortie,\n",
        "- suivie par l'activation sigmoïde. La sortie du modèle est similaire à une régression logistique.\n",
        "\n",
        "Maintenant, nous voulons coder cela en PyTorch. Une façon est d'abord d'essayer de construire un tel modèle **étape par étape**, puis de créer une classe pour tout encapsuler dans un **modèle**.\n",
        "\n",
        "## Construction du modèle, étape par étape\n",
        "\n",
        "La couche d'entrée du modèle est une couche d'Embedding. Celle-ci est déjà implémentée dans PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q25KzwFlpySU",
        "outputId": "cd77d9d1-f5d7-45e7-d60c-980e4d6ce137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input:  tensor([ 21, 316, 320,   9,  59,   8,   6])\n",
            "length:  7\n",
            "Embs shape :  torch.Size([7, 4])\n",
            "tensor([[ 0.6971, -0.9576, -1.0220,  1.3295],\n",
            "        [ 1.0256,  1.7889, -1.2001,  0.8268],\n",
            "        [-1.1081,  0.4350, -0.5725, -1.6943],\n",
            "        [-0.9530, -1.2833, -0.6837,  1.3832],\n",
            "        [ 0.2081, -0.4403,  1.3717,  0.9725],\n",
            "        [-0.5415, -1.4216, -0.0367, -1.9919],\n",
            "        [-1.3417,  0.0124, -1.3485, -0.5739]], grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ],
      "source": [
        "# build an Embedding layer\n",
        "# it is important to understand the parameters given to the constructor !\n",
        "D = 4\n",
        "embLayer = th.nn.Embedding(num_embeddings=len(lexicon), embedding_dim=D)\n",
        "# The dim of 4 is a toy example.\n",
        "# run forward on some input\n",
        "inp = texts[104]\n",
        "embs = embLayer(inp) # embLayer.forward(inp)\n",
        "# Look at the dimension of i/o\n",
        "print(\"The input: \",inp)\n",
        "print(\"length: \",len(inp))\n",
        "print(\"Embs shape : \",embs.shape)\n",
        "print(embs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  `D = 4`: `D` représente la dimension de l'embedding, c'est-à-dire la taille du vecteur que chaque mot sera transformé. Ici, 4 est choisi comme un exemple simple.\n",
        "\n",
        "2.  `embLayer = th.nn.Embedding(num_embeddings=len(lexicon), embedding_dim=D)`: C'est la création de la couche d'embedding.\n",
        "    *   `num_embeddings=len(lexicon)`: C'est le nombre total de mots uniques dans votre vocabulaire. `len(lexicon)` donne la taille du vocabulaire que vous avez chargé précédemment (5002 dans cet exemple). Chaque mot de ce vocabulaire aura un vecteur d'embedding unique.\n",
        "    *   `embedding_dim=D`: C'est la dimension de chaque vecteur d'embedding. Chaque mot sera représenté par un vecteur de 4 nombres flottants.\n",
        "\n",
        "3.  `inp = texts[104]`: Cette ligne sélectionne un exemple d'entrée, qui est le 105ème texte (index 104) de votre ensemble de données `texts`. `inp` est un tenseur d'indices de mots, comme `tensor([ 21, 316, 320, 9, 59, 8, 6])`.\n",
        "\n",
        "4.  `embs = embLayer(inp)`: Cette ligne exécute la propagation avant (`forward pass`) de la couche d'embedding. Elle prend le tenseur d'indices de mots (`inp`) et pour chaque index de mot, elle lui attribue le vecteur d'embedding correspondant de la couche `embLayer`.\n",
        "\n",
        "5.  Si l'entrée a `N` mots (ici, 7 mots), la sortie `embs` aura la forme `[N, D]`, c'est-à-dire `[7, 4]`. Chaque ligne de ce tenseur de sortie est le vecteur d'embedding de dimension `D` (4) pour le mot correspondant dans l'entrée."
      ],
      "metadata": {
        "id": "C7sX4onr0SPP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAo2OntepySV"
      },
      "source": [
        "Maintenant, nous voulons compresser le tenseur résultant le long de la dimension temporelle.\n",
        "Dans le traitement du langage naturel (NLP) et les architectures de réseaux de neurones qui traitent des séquences (comme les RNN, LSTM, Transformers), on parle souvent de la \"dimension de la séquence\" ou de la \"longueur de la séquence\" pour désigner cette dimension qui représente la succession des éléments (mots, caractères, tokens) dans le temps ou l'ordre.\n",
        "\n",
        "Le terme \"temporelle\" est très pertinent car il évoque l'idée d'une série de points de données qui se suivent, comme une série temporelle. Quand on traite un texte, on le considère comme une séquence d'événements (les mots) qui arrivent dans un certain ordre, d'où l'analogie avec le temps.\n",
        "\n",
        "Cette dimension dépend des textes d'entrée, alors que nous voulons construire une représentation de taille fixe de la phrase. La somme est une première idée.\n",
        "En additionnant les vecteurs de chaque mot, vous combinez leurs informations sémantiques. Le vecteur résultant est une sorte de \"moyenne\" ou de \"résumé\" de tous les mots présents dans la phrase. Il perd l'information sur l'ordre exact des mots, mais conserve l'information sur les mots qui étaient présents et leurs caractéristiques globales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9aqQ9aJpySV",
        "outputId": "26197125-7c58-40e5-9456-ba7270543fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7])\n",
            "torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "## compute the sum of out to create a vector of size \"embedding_dim\".\n",
        "## Of course it will be a tensor with one dimension set to \"embedding_dim\".\n",
        "sumOfEmbs = embs.sum(dim=1)\n",
        "print(sumOfEmbs.shape) # check the shape\n",
        "sumOfEmbs = embs.sum(dim=0)\n",
        "print(sumOfEmbs.shape) # check the shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fray2Zj_pySW"
      },
      "source": [
        "La couche finale est une transformation linéaire : en entrée, nous avons un vecteur de taille embedding_dim et 1 en sortie. Codons cette transformation et vérifions la forme du résultat final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA4Ekg8ypySW",
        "outputId": "8ac98391-4be8-466d-98ef-8190c74e61d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1]) tensor([0.6601], grad_fn=<SigmoidBackward>)\n",
            "torch.Size([1]) tensor([0.8424], grad_fn=<SigmoidBackward>)\n"
          ]
        }
      ],
      "source": [
        "# Compute out, after you created the Linear layer\n",
        "th.manual_seed(12) # set the seed\n",
        "W  = th.nn.Linear(in_features=D, out_features=1) # création de la couche linéaire.\n",
        "\n",
        "out_activation = th.nn.Sigmoid()\n",
        "out= out_activation( # Le résultat de la couche linéaire est passé à la fonction Sigmoïde\n",
        "    W(sumOfEmbs)) # notre représentation fixe de la phrase est passée à la couche linéaire W\n",
        "print(out.shape,out)\n",
        "\n",
        "W  = th.nn.Linear(in_features=D, out_features=1)\n",
        "out_activation = th.nn.Sigmoid()\n",
        "out= out_activation(W(sumOfEmbs))\n",
        "print(out.shape,out)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction Sigmoïde prend n'importe quelle valeur réelle et la compresse dans l'intervalle [0, 1]. Dans un contexte de classification binaire, cela peut être interprété comme la probabilité que l'entrée appartienne à la classe positive."
      ],
      "metadata": {
        "id": "8lbgSjOc6Cf2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIOT0Mm3pySW"
      },
      "source": [
        "## Encapsuler le tout dans un joli module/modèle\n",
        "\n",
        "Pour écrire votre propre module, héritez de la classe *Module*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLWaKdIEpySX"
      },
      "outputs": [],
      "source": [
        "class CBOW_classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW_classifier, self).__init__()\n",
        "        self.emb = nn.Embedding( # crée la couche d'embedding\n",
        "            vocab_size, embedding_dim) # Cette couche prendra des indices de mots en entrée et retournera leurs vecteurs d'embedding correspondants\n",
        "        self.lin = nn.Linear( # crée la couche linéaire\n",
        "            embedding_dim, 1)\n",
        "\n",
        "    def forward( # comment une entrée (inp) est transformée pour produire la sortie du modèle\n",
        "        self, inp):\n",
        "        return th.sigmoid(\n",
        "            self.lin(\n",
        "                self.emb( # convertit chaque indice de mot en son vecteur d'embedding\n",
        "                    inp).sum(\n",
        "                        dim=0)))\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "cs5wXpWwpySX"
      },
      "source": [
        "Cette classe hérite de *Module*. Ces deux méthodes sont obligatoires. Le constructeur construit un modèle avec ses paramètres initialisés. Le *forward* est pour l'inférence.\n",
        "\n",
        "Le tenseur d'embeddings résultant de l'étape précédente (qui a la forme [nombre_de_mots, embedding_dim]) est ensuite sommé le long de la dimension 0 (la dimension des mots). Cela produit un seul vecteur de taille embedding_dim, qui représente la phrase entière (le principe du Bag of Words).\n",
        "\n",
        "Dans PyTorch, un modèle prend des *Tensors (variables)* en entrée et renvoie des *Tensors (variables)*. La sortie est comparée à la vérité terrain par la fonction de perte.\n",
        "\n",
        "Prenons un exemple d'entraînement et vérifions si le passage avant (forward pass) est correct. Le résultat devrait être un *FloatTensor* avec une seule valeur : le score entre 0 et 1 attribué par le modèle à l'exemple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIlrnlyMpySX",
        "outputId": "9fd6769d-002a-4cad-875e-ffef4b306831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6236], grad_fn=<SigmoidBackward>)\n",
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "classifier = CBOW_classifier(\n",
        "    vocab_size=len(\n",
        "        lexicon),embedding_dim=10) # hyperparamètre important que vous pourrez ajuster\n",
        "print(classifier(texts[0]))\n",
        "print(labels[0]) # vrai label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette valeur est la prédiction du modèle pour le texte texts[0], représentant la probabilité que ce texte soit une critique positive. Une valeur proche de 1 indique une forte probabilité d'être positif, et une valeur proche de 0 indique une forte probabilité d'être négatif."
      ],
      "metadata": {
        "id": "iMOo9Uqu_T22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFWSldy6pySY",
        "outputId": "bb7b2097-d081-4f63-b030-ffa7884b8395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6236], grad_fn=<SigmoidBackward>)\n"
          ]
        }
      ],
      "source": [
        "print(classifier.forward(texts[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "classifier(texts[0]) est une syntaxe raccourcie et préférée pour classifier.forward(texts[0]) dans PyTorch"
      ],
      "metadata": {
        "id": "uw1sVYrI_9K9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEqE-4ippySY"
      },
      "source": [
        "## Fonction objectif\n",
        "La fonction de perte (ou fonction objectif) est adaptée au modèle et à la tâche.\n",
        "\n",
        "- Lisez la documentation du module **nn** : http://pytorch.org/docs/master/nn.html.\n",
        "- Dans notre cas, deux fonctions de perte peuvent être utilisées : *BCELoss* et *BCEWithLogitsLoss*. Comparez-les et faites votre choix.\n",
        "- Compte tenu de ce choix, vous pourriez vouloir modifier la classe *CBOW_Classifier*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOg8oBhTpySY"
      },
      "outputs": [],
      "source": [
        "## define de training function\n",
        "loss_fn = nn.BCELoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pDdDsFBmpySZ"
      },
      "source": [
        "## Entraînement\n",
        "\n",
        "Écrivons le code pour entraîner le modèle, surveiller le processus d'entraînement et évaluer le modèle à l'aide des données de test. Commençons avec un optimiseur SGD avec un taux d'apprentissage de 0,1.\n",
        "\n",
        "### Ordre aléatoire\n",
        "Dans de nombreux cas, il peut être important d'itérer sur les données dans un ordre aléatoire et non dans l'ordre dans lequel nous avons construit le corpus. Cet ordre initial peut introduire un biais dans le processus d'évaluation. Une méthode simple pour mélanger les données est de mélanger les indices que nous utilisons. Supposons que nous ayons 10 échantillons d'entraînement, nous pouvons faire quelque chose comme :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yPZ4J8ypySZ",
        "outputId": "207db18a-a6c1-461d-d9f3-508e0e18256d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "0\n",
            "2\n",
            "3\n",
            "8\n",
            "7\n",
            "9\n",
            "6\n",
            "1\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "ids = list(range(10))\n",
        "import random\n",
        "random.shuffle(ids)\n",
        "for i in ids:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est une technique courante en apprentissage automatique pour s'assurer que les données sont traitées dans un ordre non séquentiel, ce qui aide à éviter les biais et à améliorer la généralisation du modèle pendant l'entraînement."
      ],
      "metadata": {
        "id": "joNphzvbBJjd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkLbvcefpySZ"
      },
      "source": [
        "##### Maintenant, nous avons tout pour exécuter la boucle d'entraînement et tester ce modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FN8eCwkpySa",
        "outputId": "a7be379c-0a06-408e-c669-c3cb0efd7906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(0.7279) 54.54333333333334 tensor(15049.)\n",
            "1 tensor(0.6946) 58.906666666666666 tensor(15068.)\n",
            "2 tensor(0.6643) 62.86333333333334 tensor(14997.)\n",
            "3 tensor(0.6356) 65.49333333333334 tensor(15064.)\n",
            "4 tensor(0.6110) 67.36 tensor(14950.)\n",
            "5 tensor(0.5916) 68.86666666666666 tensor(14988.)\n",
            "6 tensor(0.5753) 69.91333333333333 tensor(14934.)\n",
            "7 tensor(0.5615) 71.37 tensor(14945.)\n",
            "8 tensor(0.5477) 72.33666666666667 tensor(14995.)\n",
            "9 tensor(0.5371) 72.68 tensor(14916.)\n"
          ]
        }
      ],
      "source": [
        "total = len(texts)\n",
        "randomidx = list(range(total))\n",
        "preds = th.zeros(\n",
        "    total) # sera utilisé pour stocker les prédictions du modèle pour chaque exemple à la fin de chaque époque.\n",
        "optimizer = th.optim.SGD(\n",
        "    classifier.parameters(\n",
        "\n",
        "    ),lr=1e-2) # détermine la taille des pas effectués lors de la mise à jour des poids\n",
        "Nepochs = 10\n",
        "losses = th.zeros(\n",
        "    Nepochs) # Initialise un tenseur pour stocker la perte moyenne de chaque époque\n",
        "for epoch in range(Nepochs):\n",
        "    total_loss = th.Tensor(\n",
        "        [0]) # Réinitialise la perte totale accumulée pour l'époque courante à 0\n",
        "    correct=0 # Réinitialise le compteur de prédictions correctes pour l'époque courante à 0\n",
        "    random.shuffle(\n",
        "        randomidx) # éviter l'apprentissage de motifs liés à l'ordre des données plutôt qu'aux données elles-mêmes\n",
        "    for i in randomidx:\n",
        "        classifier.zero_grad(\n",
        "\n",
        "        )\n",
        "        x = texts[\n",
        "            i] # Récupère le texte (séquence d'indices de mots) pour l'exemple courant\n",
        "        probs = classifier(\n",
        "            x)[0] # extraire la seule valeur scalaire de probabilité du tenseur de sortie\n",
        "        loss = loss_fn(\n",
        "            probs, labels[\n",
        "                i]) # perte (erreur) entre la probabilité prédite et le vrai label\n",
        "        pred= probs>0.5\n",
        "        preds[i] = pred\n",
        "        if pred.item(\n",
        "\n",
        "        ) == labels[ # Vérifie si la prédiction correspond au vrai label\n",
        "            i].item() :\n",
        "            correct +=1\n",
        "        loss.backward(\n",
        "\n",
        "        ) # calcule les gradients de la fonction de perte par rapport à tous les paramètres du modèle\n",
        "        optimizer.step(\n",
        "\n",
        "        ) # Met à jour les poids du modèle\n",
        "        total_loss += loss.data\n",
        "    losses[epoch] = total_loss/total # perte moyenne pour l'époque\n",
        "    print(epoch, losses[epoch], 100.0*correct/total, preds.sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   epoch : Le numéro de l'époque.\n",
        "*   losses[epoch] : La perte moyenne de l'époque.\n",
        "*   100.0*correct/total : L'exactitude (accuracy) du modèle sur l'ensemble du jeu de données pour cette époque (en pourcentage).\n",
        "*   preds.sum() : Le nombre total de prédictions positives faites par le modèle sur l'ensemble du jeu de données. Cela peut donner une idée du biais du modèle (s'il prédit trop souvent positif ou négatif)."
      ],
      "metadata": {
        "id": "SugUaQPGHJ3_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvduf49XpySa",
        "outputId": "1435f946-064f-47ef-c8f8-f1fc951d87ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f57963942d0>]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lejz2by5pySa"
      },
      "source": [
        "# First Experiments\n",
        "\n",
        "- Make experiments  with  2000 to start then all the data for training (equally distributed between positive and negative examples).\n",
        "- You should create a development and test sets.\n",
        "- Test different parametrization of the model (here the embedding size) and the hyper-parameter (the learning rate) for each setups.\n",
        "- Compare these different setups (loss function on the train and also the classification accuracy).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdNAgkrLpySa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WkBH35wpySa"
      },
      "source": [
        "# A deeper model\n",
        "\n",
        "We can add a hidden layer to the previous classifier.\n",
        "- Do the same as before with the different setups\n",
        "- Find the good choice of hyper-parameters.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf5frvuhpySb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}