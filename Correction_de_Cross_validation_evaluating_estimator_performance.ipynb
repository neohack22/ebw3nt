{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/ebw3nt/blob/main/Correction_de_Cross_validation_evaluating_estimator_performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIJ4plnQqH86",
        "outputId": "25c65be1-dd63-4616-f7fc-292659745e51"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **`from sklearn import svm`**\n",
        "\n",
        "   * Tu importes le module `svm` de scikit-learn, qui permet de créer des **Support Vector Machines** (SVM).\n",
        "   * Les SVM sont des modèles de classification (et régression) qui cherchent à séparer les classes dans l’espace des features par des hyperplans optimaux.\n",
        "\n",
        "2. **`X, y = datasets.load_iris(return_X_y=True)`**\n",
        "\n",
        "   * `datasets.load_iris()` charge le célèbre **jeu de données Iris**, qui contient 150 échantillons de fleurs répartis en 3 espèces.\n",
        "   * `X` contient les **features** (longueur et largeur des sépales et pétales), donc une matrice de 150×4.\n",
        "   * `y` contient les **labels**, c’est-à-dire l’espèce de chaque fleur (0, 1 ou 2).\n",
        "   * L’option `return_X_y=True` renvoie directement les deux tableaux séparés, au lieu d’un objet plus complexe."
      ],
      "metadata": {
        "id": "w91gDB1oWpfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 1. Séparer les données en **jeu d’entraînement** et **jeu de test**, en réservant **40 % des données pour le test**.\n",
        "> 2. Fixer un **random_state = 0** pour que les résultats soient reproductibles.\n",
        "> 3. Afficher la **taille** des tableaux d’entraînement `X_train` et `y_train`.\n",
        "\n",
        "**Questions guidées :**\n",
        "\n",
        "* Quelle fonction de `sklearn` permet de diviser les données de cette manière ?\n",
        "* Comment vérifier rapidement les dimensions des arrays obtenus ?\n",
        "\n",
        "**Bonus challenge :**\n",
        "\n",
        "* Essayez avec un test_size différent (par exemple 0.3) et observez ce qui change."
      ],
      "metadata": {
        "id": "3VbaT79cX2xD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdCOLrVAqyc6",
        "outputId": "c5b911a0-20b3-427e-bf9b-916187e6b2b6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((90, 4), (90,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHnU3UmUtqmk",
        "outputId": "80fdab24-b199-4ef1-c80b-5aa752826059"
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60, 4), (60,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LJOrYo9kYIm5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUCIFXx3t556",
        "outputId": "d79ba95f-03cc-4ccf-c0db-1f624190375a"
      },
      "source": [
        "# clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "clm = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "clm.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un **SVM** cherche à séparer des données en **deux classes**. L’**hyperplan** est simplement la \"ligne\" (en 2D) ou le \"plan\" (en 3D) qui sépare ces deux classes.\n",
        "\n",
        "* En 2 dimensions, c’est une droite.\n",
        "* En 3 dimensions, c’est un plan.\n",
        "* Dans plus de 3 dimensions, c’est un **hyperplan**, mais le concept est le même : il sépare l’espace en deux parties, chacune correspondant à une classe.\n",
        "\n",
        "Le SVM cherche **l’hyperplan qui maximise la marge**, c’est-à-dire la distance entre les points les plus proches de chaque classe (appelés **vecteurs de support**) et l’hyperplan.\n",
        "\n",
        "---\n",
        "\n",
        "Le paramètre `C` contrôle **l’équilibre entre la précision sur les données d’entraînement et la simplicité de l’hyperplan** :\n",
        "\n",
        "* **C grand (ex. 1000)** : le modèle essaie de **corriger toutes les erreurs d’entraînement**, même si l’hyperplan devient très complexe.\n",
        "* **C petit (ex. 0.1)** : le modèle tolère **quelques erreurs sur l’entraînement**, pour avoir un hyperplan plus simple et qui **généralise mieux** sur de nouvelles données.\n",
        "\n",
        "Image :\n",
        "\n",
        "* Grand C → tu colles l’hyperplan à chaque point (risque de surapprentissage).\n",
        "* Petit C → tu laisses quelques points \"mal classés\" mais le modèle est plus robuste."
      ],
      "metadata": {
        "id": "ePNQqQi1Y5oq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhRQxHevsBq"
      },
      "source": [
        "\\### Calcul de métriques validées par validation croisée"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Créer un **classifieur SVM** avec un **kernel linéaire** et un paramètre `C=1`.\n",
        "2. Évaluer la performance de votre modèle à l’aide de la **validation croisée à 5 plis**.\n",
        "3. Afficher les **scores de chaque pli** pour analyser la stabilité de votre modèle.\n",
        "\n",
        "> Indice : Utilisez `sklearn.model_selection.cross_val_score` et `sklearn.svm.SVC`.\n",
        "\n",
        "**Objectifs pédagogiques :**\n",
        "\n",
        "* Comprendre comment utiliser un SVM avec kernel linéaire.\n",
        "* Appliquer la validation croisée pour estimer la performance d’un modèle.\n",
        "* Interpréter les scores obtenus sur différents folds."
      ],
      "metadata": {
        "id": "gX7W6crzZ7Er"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg9Bhma8uIt8",
        "outputId": "c970921c-9f1b-4076-fbf9-9a005d5ba500"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eXHanmPwKyx",
        "outputId": "391fc6b4-3d1e-4caa-fe9a-3d986a1d332d"
      },
      "source": [
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98 accuracy with a standard deviation of 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L’écart-type **mesure la dispersion des valeurs autour de la moyenne**.\n",
        "\n",
        "* Si les valeurs sont très proches de la moyenne → écart-type petit.\n",
        "* Si les valeurs sont très éparpillées → écart-type grand.\n",
        "\n",
        "Supposons que tu as les scores d’un modèle sur 5 tests :\n",
        "\n",
        "```\n",
        "scores = [80, 82, 78, 79, 81]\n",
        "```\n",
        "\n",
        "* Moyenne : (80+82+78+79+81)/5 = 80\n",
        "* Écart par rapport à la moyenne :\n",
        "\n",
        "  * 80 → 0\n",
        "  * 82 → +2\n",
        "  * 78 → -2\n",
        "  * 79 → -1\n",
        "  * 81 → +1\n",
        "\n",
        "L’écart-type combine ces écarts (en les mettant au carré, en faisant la moyenne, puis en prenant la racine) pour donner une **mesure unique de dispersion**. Ici, il serait petit (≈1.58) car les scores sont proches de 80.\n",
        "\n",
        "* Pour un modèle de machine learning : si l’écart-type des scores de validation croisée est petit, ton modèle **est stable**.\n",
        "* Si l’écart-type est grand, les performances varient beaucoup selon les sous-ensembles de données, et le modèle est **moins fiable**."
      ],
      "metadata": {
        "id": "yvajPXcwaYcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Évaluez la performance de votre modèle en utilisant une validation croisée 5 folds et le score F1 macro.\n",
        "Affichez la liste des scores obtenus pour chaque fold."
      ],
      "metadata": {
        "id": "Eve0__x5a47U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yIhnqL8wgzD",
        "outputId": "bb99bcb9-f095-4711-ec38-fda75bf1b921"
      },
      "source": [
        "from sklearn import metrics\n",
        "scores = cross_val_score(\n",
        "    clf, X, y, cv=5, scoring='f1_macro')\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Votre objectif est de **tester la robustesse de votre modèle** en utilisant une technique de validation croisée qui mélange aléatoirement les échantillons à chaque itération.\n",
        ">\n",
        "> 1. Créez un objet de validation croisée qui divise vos données en 5 itérations, avec **30 % des données utilisées pour le test à chaque fois**. Assurez-vous que les tirages soient reproductibles.\n",
        "> 2. Utilisez cet objet pour **évaluer la performance de votre classifieur** et afficher les scores pour chaque itération.\n",
        ">\n",
        "> *Indice : la classe `ShuffleSplit` de `sklearn.model_selection` peut vous être utile.*"
      ],
      "metadata": {
        "id": "YhZ0SrOUbHe_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgWp_cBcxYbr",
        "outputId": "9c594ef4-0299-4271-f13a-acc56254667d"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "n_samples = X.shape[0]\n",
        "# cv = ShuffleSplit(n_split=5, test_size=0.3, random_state=0)\n",
        "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "cross_val_score(clf, X, y, cv=cv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 1. Écrivez une fonction `custom_cv_2folds(X)` qui, à chaque itération, retourne les indices de train et test pour un pli.\n",
        "> 2. Assurez-vous que votre fonction peut être utilisée directement avec `cross_val_score` de `scikit-learn`.\n",
        "> 3. Testez votre fonction sur un classifieur `clf` et les données `X`, `y`.\n",
        "\n",
        "**Points à réfléchir :**\n",
        "\n",
        "* Comment diviser votre jeu de données en 2 moitiés égales pour les folds ?\n",
        "* Quelle structure Python permet de renvoyer les indices **au fur et à mesure** pour chaque fold ?\n",
        "* Pourquoi utiliser `np.arange` plutôt que `range` pour les indices ?\n",
        "\n",
        "**Bonus challenge :**\n",
        "\n",
        "* Modifiez votre fonction pour qu’elle accepte un nombre variable de folds (`n_folds`) et fonctionne pour n’importe quelle taille de dataset.\n"
      ],
      "metadata": {
        "id": "2ll968arbfPu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roWDkIP06gqX",
        "outputId": "9fb27fe2-539d-435c-b8f7-c6f06ce948f0"
      },
      "source": [
        "def custom_cv_2folds(X):\n",
        "  n = X.shape[0]\n",
        "  i = 1\n",
        "  while i<= 2:\n",
        "    # idx = np.arrange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
        "    idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
        "    yield idx, idx\n",
        "    i += 1\n",
        "\n",
        "custom_cv = custom_cv_2folds(X)\n",
        "cross_val_score(clf, X, y, cv=custom_cv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.97333333])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Comment pouvez-vous séparer vos données en un jeu d’entraînement (60%) et un jeu de test (40%) tout en assurant la reproductibilité des résultats ?\n",
        "2. Quel type de transformation appliqueriez-vous sur `X_train` pour que chaque feature ait une moyenne de 0 et un écart type de 1 ? Comment appliquer la même transformation sur `X_test` ?\n",
        "3. En utilisant `sklearn`, quel modèle SVM pouvez-vous entraîner sur vos données normalisées ?\n",
        "4. Comment mesurer la **précision** de votre modèle sur le jeu de test ?"
      ],
      "metadata": {
        "id": "bVFIOr63dZQ4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTJP1gjT89dt",
        "outputId": "32d5cde3-50bc-4c64-a01e-8a35f84e001a"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=0\n",
        ")\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)\n",
        "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
        "X_test_transformed = scaler.transform(X_test)\n",
        "clf.score(X_test_transformed, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gscmeIrG_U07",
        "outputId": "b964e7d2-a00b-4344-cf32-eb21625e4220"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
        "cross_val_score(clf, X, y, cv=cv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction `make_pipeline` permet de **chaîner plusieurs étapes de traitement** et un modèle final.\n",
        "Chaque étape peut être, par exemple :\n",
        "\n",
        "* une transformation des données (standardisation, encodage, etc.)\n",
        "* un modèle de machine learning\n",
        "\n",
        "Cela simplifie la préparation et l’entraînement, car tout se fait **dans un seul objet**.\n",
        "\n",
        "---\n",
        "\n",
        "`StandardScaler` est un **préprocesseur** qui :\n",
        "\n",
        "* centre les données autour de 0\n",
        "* les met à l’échelle avec un écart-type de 1\n",
        "\n",
        "En gros, chaque caractéristique (feature) devient comparable, ce qui est important pour des modèles sensibles à l’échelle, comme le **SVM**."
      ],
      "metadata": {
        "id": "5xAKQxy6eQug"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17KEsxJ7_4xW"
      },
      "source": [
        "#### La fonction cross_validate et l'évaluation de plusieurs métriques"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Créer un classificateur SVM linéaire avec `C=1` et `random_state=0`.\n",
        "2. Évaluer ce modèle en utilisant **la validation croisée** sur tout le jeu de données.\n",
        "3. Calculer au moins deux métriques de performance pour chaque pli : **précision macro** et **rappel macro**.\n",
        "4. Stocker les résultats dans un objet `scores` et afficher toutes les clés disponibles après l’évaluation.\n",
        "\n",
        "**Questions-guides :**\n",
        "\n",
        "* Quelle fonction de scikit-learn permet de faire une validation croisée et récupérer plusieurs métriques à la fois ?\n",
        "* Comment spécifier les métriques que vous voulez calculer ?\n",
        "* Comment instancier un SVM linéaire avec des paramètres spécifiques ?\n",
        "\n",
        "**Bonus :** Essayez d’ajouter la métrique `f1_macro` et observez comment les résultats changent.\n"
      ],
      "metadata": {
        "id": "Rjh4n2gWf11P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdLMXZTF_yCe",
        "outputId": "3b1eefb8-ec03-46aa-a43e-190eb6b8455c"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import recall_score\n",
        "scoring = ['precision_macro', 'recall_macro']\n",
        "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
        "scores = cross_validate(clf, X, y, scoring=scoring)\n",
        "sorted(scores.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvJe4h90CNIS",
        "outputId": "ed3d0983-e720-4ccc-9635-e359c246f169"
      },
      "source": [
        "scores['test_recall_macro']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`scores['test_recall_macro']` contient le **rappel moyen macro calculé sur l’ensemble de test** (ou via une validation croisée si tu utilises `cross_validate`)."
      ],
      "metadata": {
        "id": "w5PI-do0gaHo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsnBdw5pCQ35",
        "outputId": "21eefe9f-2f75-4e9e-fd80-503a5449e8c9"
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "scoring = {'prec_macro': 'precision_macro',\n",
        "           'rec_macro': make_scorer(recall_score, average='macro')}\n",
        "scores = cross_validate(clf, X, y, scoring=scoring,\n",
        "                        cv=5, return_train_score=True)\n",
        "sorted(scores.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fit_time',\n",
              " 'score_time',\n",
              " 'test_prec_macro',\n",
              " 'test_rec_macro',\n",
              " 'train_prec_macro',\n",
              " 'train_rec_macro']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code permet d’évaluer un modèle de classification sur plusieurs métriques (précision et rappel), de façon robuste grâce à la validation croisée. On peut comparer les performances sur l’entraînement et le test pour détecter un surapprentissage.\n",
        "\n",
        "* `precision_macro` : la précision moyenne sur toutes les classes.\n",
        "* `rec_macro` : le rappel moyen sur toutes les classes, créé avec `make_scorer` pour transformer la fonction `recall_score` en objet que `cross_validate` peut utiliser.\n",
        "\n",
        "> On choisit `macro` pour traiter toutes les classes de façon **égale**, même si certaines sont minoritaires.\n",
        "\n",
        "```python\n",
        "sorted(scores.keys())\n",
        "```\n",
        " liste toutes les clés disponibles dans le dictionnaire `scores`.\n",
        "* Typiquement, on y trouve :\n",
        "\n",
        "  * `'fit_time'` → temps pour entraîner le modèle\n",
        "  * `'score_time'` → temps pour prédire\n",
        "  * `'test_prec_macro'` → précision macro sur test\n",
        "  * `'train_prec_macro'` → précision macro sur train\n",
        "  * `'test_rec_macro'` → rappel macro sur test\n",
        "  * `'train_rec_macro'` → rappel macro sur train"
      ],
      "metadata": {
        "id": "TusxGU_qhC2G"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjyEFMnrEdBJ",
        "outputId": "a9f893f0-af8b-4b7a-ec46-29961c89ea64"
      },
      "source": [
        "scores['train_rec_macro']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.975     , 0.975     , 0.99166667, 0.98333333, 0.98333333])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Utilisez la validation croisée à 5 folds pour calculer la **précision moyenne** (`precision_macro`) de votre modèle.\n",
        "> 2. Faites en sorte de **récupérer les classifieurs entraînés à chaque pli**.\n",
        "> 3. Inspectez la structure du résultat pour voir quelles informations sont disponibles (affichez les **clés** du dictionnaire retourné).\n",
        ">\n",
        "> **Indice** : pensez à une fonction de `sklearn.model_selection` qui permet de retourner à la fois les scores et les estimateurs."
      ],
      "metadata": {
        "id": "oghdb_r2iCYI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHC5vefbEkFc",
        "outputId": "a1102fe8-091a-4891-9814-0eba1c7cff32"
      },
      "source": [
        "scores = cross_validate(clf, X, y,\n",
        "                        scoring='precision_macro', cv=5,\n",
        "                        return_estimator=True)\n",
        "sorted(scores.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estimator', 'fit_time', 'score_time', 'test_score']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jauFl8PGFH8"
      },
      "source": [
        "### Cross validation iterators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESVlbS9DGwdJ"
      },
      "source": [
        "#### Cross-validation iterators for i.i.d. data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KneKab1Hjzr"
      },
      "source": [
        "##### K-fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WKNRpT3GAEs",
        "outputId": "78e3e5ea-eaf5-4b44-83f2-eaf5d0ee05e0"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "X = [\"a\", \"b\", \"c\", \"d\"]\n",
        "kf = KFold(n_splits=2)\n",
        "for train, test in kf.split(X):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3] [0 1]\n",
            "[0 1] [2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "À chaque tour, on change la partie test pour valider la robustesse du modèle.\n",
        "\n",
        "* `KFold` divise votre dataset en `n_splits` parties égales (ici 2).\n",
        "* Chaque partie servira **une fois de test**, les autres parties serviront à l’entraînement.\n",
        "* Exemple : si on a 6 observations et `n_splits=2` :\n",
        "\n",
        "  * Split 1 : train = [0,1,2], test = [3,4,5]\n",
        "  * Split 2 : train = [3,4,5], test = [0,1,2]\n",
        "\n",
        "---\n",
        "\n",
        "* `kf.split(X)` renvoie **les indices** des données pour l’entraînement (`train`) et le test (`test`) à chaque split.\n",
        "* Dans la boucle, on peut :\n",
        "\n",
        "  * **Entraîner le modèle** sur `X[train]`\n",
        "  * **Tester le modèle** sur `X[test]`"
      ],
      "metadata": {
        "id": "GYV5UrMxjjoO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpUvIrxgILq6"
      },
      "source": [
        "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
        "y = np.array([0, 1, 0, 1])\n",
        "#\n",
        "X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg6Bs1_MJo2D"
      },
      "source": [
        "##### Repeated K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02c1R22iJfjU",
        "outputId": "039f62f0-d745-433f-eacb-a773fa5f36d1"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "random_state = 12883823\n",
        "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)\n",
        "for train, test in rkf.split(X):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3] [0 1]\n",
            "[0 1] [2 3]\n",
            "[0 2] [1 3]\n",
            "[1 3] [0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`RepeatedKFold` est une technique de **validation croisée répétée**.\n",
        "\n",
        "* `n_splits=2` : on divise les données en 2 groupes (folds).\n",
        "* `n_repeats=2` : on répète ce processus **2 fois**, avec un nouveau découpage à chaque fois.\n",
        "* `random_state=12883823` : assure que la partition est **répétable** (on obtient toujours les mêmes splits si on relance le code).\n",
        "\n",
        "Chaque “split” donne :\n",
        "\n",
        "* `train` : les indices des lignes utilisées pour l’entraînement.\n",
        "* `test` : les indices des lignes utilisées pour le test.\n",
        "\n",
        "---\n",
        "\n",
        "* `rkf.split(X)` génère **tous les ensembles train/test** de toutes les répétitions.\n",
        "* Le `print` affiche les indices des observations choisies pour l’entraînement et le test à chaque étape.\n",
        "\n",
        "Pour notre exemple, on aura 4 affichages au total : 2 splits × 2 répétitions.\n",
        "\n",
        "---\n",
        "\n",
        "**Différence avec KFold simple :** ici, on répète la validation croisée pour réduire l’effet de la variance liée au découpage aléatoire."
      ],
      "metadata": {
        "id": "GKAupbvoy5HS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwr-_ouHKjgp"
      },
      "source": [
        "##### Leave One Out (LOO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1m0Pvf1KgUu",
        "outputId": "52084136-4032-4b88-8e0c-3b58e8cf4174"
      },
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "X = [1, 2, 3, 4]\n",
        "loo = LeaveOneOut()\n",
        "for train, test in loo.split(X):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3] [0]\n",
            "[0 2 3] [1]\n",
            "[0 1 3] [2]\n",
            "[0 1 2] [3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave-One-Out est une **méthode de validation croisée** utilisée pour évaluer la performance d’un modèle prédictif.\n",
        "Le principe est simple :\n",
        "\n",
        "* On prend **un échantillon de données** de taille (n).\n",
        "* On entraîne le modèle sur **tous les points sauf un**.\n",
        "* On teste le modèle sur **le point laissé de côté**.\n",
        "* On répète cette opération **pour chaque point du jeu de données**.\n",
        "\n",
        "En résumé : chaque observation est utilisée **exactement une fois pour tester** et **n-1 fois pour entraîner**.\n",
        "\n",
        "---\n",
        "\n",
        "* ✅ **Fiable pour les petits jeux de données**, car on maximise l’utilisation de chaque point (<100 observations).\n",
        "* ✅ Permet d’obtenir une **estimation presque non biaisée** de la performance réelle du modèle.\n",
        "* ⚠️ Cependant, c’est **très coûteux en calcul** si le dataset est grand.\n",
        "\n",
        "---\n",
        "\n",
        "Imaginez que vous formez un modèle pour prédire si un client va souscrire un produit financier (oui/non), avec 5 clients :\n",
        "\n",
        "| Client | X (donnée) | Y (souscription) |\n",
        "| ------ | ---------- | ---------------- |\n",
        "| 1      | 10         | Oui              |\n",
        "| 2      | 15         | Non              |\n",
        "| 3      | 20         | Oui              |\n",
        "| 4      | 25         | Non              |\n",
        "| 5      | 30         | Oui              |\n",
        "\n",
        "**Étapes LOO :**\n",
        "\n",
        "1. On retire le client 1 du dataset.\n",
        "2. On entraîne le modèle sur les clients 2 à 5.\n",
        "3. On prédit la souscription du client 1 et on mesure l’erreur.\n",
        "4. On répète pour chaque client.\n",
        "5. On calcule **l’erreur moyenne** sur tous les clients."
      ],
      "metadata": {
        "id": "p92xckNEzeO4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZLP4zdnNhS7"
      },
      "source": [
        "##### Leave P Out (LPO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlAdI5SUMiej",
        "outputId": "fc2abcec-3f8f-40e9-9ac7-860c692be9c1"
      },
      "source": [
        "from sklearn.model_selection import LeavePOut\n",
        "\n",
        "X = np.ones(4)\n",
        "lpo = LeavePOut(p=2)\n",
        "for train, test in lpo.split(X):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3] [0 1]\n",
            "[1 3] [0 2]\n",
            "[1 2] [0 3]\n",
            "[0 3] [1 2]\n",
            "[0 2] [1 3]\n",
            "[0 1] [2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave-P-Out est une méthode de **validation croisée**. Son objectif : tester la performance d’un modèle sur des données qu’il n’a **jamais vues** pendant l’entraînement.\n",
        "\n",
        "* “P” signifie le **nombre d’exemples laissés de côté** à chaque itération.\n",
        "* On entraîne le modèle sur toutes les données **sauf P**.\n",
        "* On teste le modèle sur ces **P exemples laissés de côté**.\n",
        "* On répète le processus **pour toutes les combinaisons possibles** de P exemples.\n",
        "\n",
        "Supposons que vous ayez 5 observations (A, B, C, D, E) et que vous choisissiez **P = 2** :\n",
        "\n",
        "* Première combinaison de test : (A, B), entraînement sur (C, D, E)\n",
        "* Deuxième combinaison : (A, C), entraînement sur (B, D, E)\n",
        "* … et ainsi de suite pour toutes les combinaisons de 2 observations.\n",
        "\n",
        "À la fin, on fait la **moyenne des performances** sur toutes les combinaisons pour obtenir une estimation fiable de la qualité du modèle.\n",
        "\n",
        "---\n",
        "\n",
        "### Avantages\n",
        "\n",
        "* Très **précis**, car le modèle est testé sur toutes les combinaisons possibles.\n",
        "* Idéal pour des **petits jeux de données**.\n",
        "\n",
        "---\n",
        "\n",
        "### Inconvénients\n",
        "\n",
        "* **Très coûteux en calcul** : le nombre de combinaisons est C(n, p)\n",
        "* Pour de grands jeux de données, il devient **impraticable**.\n",
        "* Rarement utilisé dans les grands projets : on préfère des alternatives comme K-Fold Cross-Validation.\n",
        "\n",
        "---\n",
        "\n",
        "### Quand l’utiliser\n",
        "\n",
        "* **Petites datasets** où chaque observation compte.\n",
        "* Quand on veut une **estimation très fiable** de la performance d’un modèle.\n",
        "* Pour des études **académiques ou expérimentales**."
      ],
      "metadata": {
        "id": "MqQNLgG-0Caw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqrzM1ZvOEyJ"
      },
      "source": [
        "##### Validation croisée par permutations aléatoires (ou Shuffle & Split)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wek8QFryOBNw",
        "outputId": "cad3d134-7f5a-4340-c886-1ba0b2a6d25c"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "X = np.arange(10)\n",
        "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
        "for train_index, test_index in ss.split(X):\n",
        "  print(\"%s %s\" % (train_index, test_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 1 6 7 3 0 5] [2 8 4]\n",
            "[2 9 8 0 6 7 4] [3 5 1]\n",
            "[4 5 1 0 6 9 7] [2 3 8]\n",
            "[2 7 5 8 0 3 4] [6 1 9]\n",
            "[4 1 0 6 8 9 3] [5 2 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au lieu de simplement couper vos données en **train** et **test** une seule fois, ShuffleSplit :\n",
        "\n",
        "* Mélange (**shuffle**) les données de manière aléatoire.\n",
        "* Les divise ensuite en **train/test** plusieurs fois.\n",
        "* Cela permet d’avoir plusieurs évaluations du modèle sur différentes portions des données.\n",
        "\n",
        "C’est particulièrement utile si :\n",
        "\n",
        "* Vous avez peu de données.\n",
        "* Vous voulez éviter que votre résultat dépende d’une seule séparation des données.\n",
        "\n",
        "---\n",
        "\n",
        "### Comment ça fonctionne concrètement ?\n",
        "\n",
        "Imaginons un dataset de 1000 observations :\n",
        "\n",
        "* Vous décidez que 80 % seront pour l’entrainement, 20 % pour le test.\n",
        "* ShuffleSplit va **répéter ce découpage N fois** (par exemple 5 fois).\n",
        "* À chaque répétition, les données sont **mélangées différemment**, donc le modèle est évalué sur des ensembles tests différents à chaque fois.\n",
        "\n",
        "Résultat : vous obtenez une distribution de scores plus **fiable et représentative** des performances réelles.\n",
        "\n",
        "---\n",
        "\n",
        "### Pourquoi c’est intéressant pour des professionnels\n",
        "\n",
        "* **Fiabilité** : évite de tirer des conclusions basées sur un seul découpage.\n",
        "* **Flexibilité** : on peut ajuster la taille du test et le nombre de répétitions.\n",
        "* **Simplicité** : facile à intégrer dans vos pipelines de validation."
      ],
      "metadata": {
        "id": "3gmBIonJ1PyP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cTV7nT-QRNy"
      },
      "source": [
        "#### Cross-validation iterators with stratification based on class labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3CpQVqFQTXf"
      },
      "source": [
        "##### Stratified k-fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmTjJTrIP9AK",
        "outputId": "dfd4ef7d-34c1-4b3f-f17d-878061c9647b"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import numpy as np\n",
        "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "for train, test in skf.split(X, y):\n",
        "  print('train -  {}    | test  -   {}'.format(\n",
        "      np.bincount(y[train]), np.bincount(y[test])))\n",
        "#  ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train -  [30  3]    | test  -   [15  2]\n",
            "train -  [30  3]    | test  -   [15  2]\n",
            "train -  [30  4]    | test  -   [15  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, le problème est que les classes sont **déséquilibrées** : 0 est très majoritaire, 1 très minoritaire. Si on fait un simple découpage aléatoire, certains sous-ensembles pourraient **ne pas contenir de 1**, ce qui poserait problème pour l’évaluation.\n",
        "\n",
        "---\n",
        "\n",
        "`StratifiedKFold` est une variante de KFold qui **préserve la proportion de chaque classe dans chaque pli (fold)**.\n",
        "\n",
        "* `n_splits=3` → on découpe les données en 3 sous-ensembles.\n",
        "* `skf.split(X, y)` → retourne, pour chaque pli, les indices des données d’entraînement (`train`) et de test (`test`).\n",
        "\n",
        "---\n",
        "\n",
        "`np.bincount(y[train])` compte combien d’exemples de chaque classe sont dans le train (et pareil pour test).\n",
        "\n",
        "Donc, on **voit la répartition des classes dans chaque fold**.\n",
        "\n",
        "Par exemple, une sortie typique pourrait être :\n",
        "\n",
        "```\n",
        "train -  [30 3]    | test  -   [15 2]\n",
        "train -  [30 3]    | test  -   [15 0]\n",
        "train -  [31 2]    | test  -   [14 3]\n",
        "```\n",
        "\n",
        "* Les `0` et `1` sont **répartis de manière équilibrée selon leur proportion initiale**.\n",
        "* On évite d’avoir un test set sans aucune instance minoritaire."
      ],
      "metadata": {
        "id": "mMWZWi1T2hFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Diviser votre dataset en **3 folds** pour une validation croisée.\n",
        "2. Pour chaque fold, récupérer les indices de l’ensemble d’entraînement et de test.\n",
        "3. Afficher la répartition des classes (`y`) dans les ensembles d’entraînement et de test pour chaque fold.\n",
        "\n",
        "**Indices :**\n",
        "\n",
        "* Utilisez `KFold` de `sklearn.model_selection`.\n",
        "* Les indices de train/test sont donnés par `kf.split(X, y)`.\n",
        "* `np.bincount` peut vous aider à compter le nombre d’occurrences de chaque classe.\n",
        "\n",
        "**Attendu (exemple de sortie) :**\n",
        "\n",
        "```\n",
        "train  -   [40 40]    |   test  -   [20 20]\n",
        "train  -   [40 40]    |   test  -   [20 20]\n",
        "train  -   [40 40]    |   test  -   [20 20]\n",
        "```"
      ],
      "metadata": {
        "id": "G1Y4GQNq8gYh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi5Ns5zbSdyv",
        "outputId": "14998b78-5489-45fd-f61e-746efdce7c8d"
      },
      "source": [
        "kf = KFold(n_splits=3)\n",
        "for train, test in kf.split(X, y):\n",
        "  print('train  -   {}    |   test  -   {}'.format(\n",
        "      np.bincount(y[train]), np.bincount(y[test])\n",
        "  ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  -   [28  5]    |   test  -   [17]\n",
            "train  -   [28  5]    |   test  -   [17]\n",
            "train  -   [34]    |   test  -   [11  5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ12rYDnTk14"
      },
      "source": [
        "#### Itérateurs de validation croisée pour les données groupées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWxhVlLHUZP9"
      },
      "source": [
        "##### K-fold de groupe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AJYU0a6TDHj",
        "outputId": "24fa858f-f85b-454a-e227-e29f31e520b0"
      },
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
        "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]\n",
        "groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
        "\n",
        "gkf = GroupKFold(n_splits=3)\n",
        "for train, test in gkf.split(X, y, groups=groups):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5] [6 7 8 9]\n",
            "[0 1 2 6 7 8 9] [3 4 5]\n",
            "[3 4 5 6 7 8 9] [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`GroupKFold` est une **méthode de validation croisée** (cross-validation) utilisée quand on a des **groupes de données liés** et qu’on ne veut pas que des observations provenant du même groupe se retrouvent à la fois dans l’ensemble d’entraînement et dans l’ensemble de test.\n",
        "\n",
        "* Exemple concret :\n",
        "\n",
        "  * Vous entraînez un modèle sur des patients pour prédire une maladie.\n",
        "  * Chaque patient peut avoir plusieurs observations (mesures à différents moments).\n",
        "  * Si certaines mesures du même patient apparaissent à la fois dans l’entraînement et le test, le modèle \"triche\" car il voit des données très similaires.\n",
        "  * **Solution : utiliser `GroupKFold`** pour que toutes les observations d’un patient soient dans **le même fold**, soit entraînement, soit test.\n",
        "\n",
        "---\n",
        "\n",
        "1. On fournit :\n",
        "\n",
        "   * `X` : les données (features)\n",
        "   * `y` : les labels (cibles)\n",
        "   * `groups` : un vecteur qui indique à quel groupe appartient chaque observation\n",
        "\n",
        "2. `GroupKFold` divise les données en `k` folds de manière à ce que **aucun groupe ne soit partagé entre les folds**.\n",
        "\n",
        "3. Pour chaque itération :\n",
        "\n",
        "   * Un fold devient le **test set**\n",
        "   * Les autres folds deviennent le **train set**\n",
        "\n",
        "\n",
        "\n",
        "**Les groupes ne sont jamais mélangés** entre train et test.\n",
        "\n",
        "---\n",
        "\n",
        "* Évite le **faux optimisme** du modèle.\n",
        "* Garantit que le modèle est testé sur des **données vraiment inédites**, pas sur des variations très proches de celles vues à l’entraînement.\n",
        "* Très utile dans :\n",
        "\n",
        "  * Médecine (patients)\n",
        "  * Marketing (clients)\n",
        "  * Industrie (machines ou sites)"
      ],
      "metadata": {
        "id": "t-MmFdwJ_j3v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "927DWD7eX7yt"
      },
      "source": [
        "##### StratifiedGroupKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD0rnuZbfTfd"
      },
      "source": [
        "##### Leave One Group Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oumT-eIcZ0y_",
        "outputId": "4aa8703c-0ba8-4688-c1ff-9ae1e3417338"
      },
      "source": [
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "\n",
        "X = [1, 5, 10, 50, 60, 70, 80]\n",
        "y = [0, 1, 1, 2, 2, 2, 2]\n",
        "groups = [1, 1, 2, 2, 3, 3, 3]\n",
        "logo = LeaveOneGroupOut()\n",
        "for train, test in logo.split(X, y, groups=groups):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 4 5 6] [0 1]\n",
            "[0 1 4 5 6] [2 3]\n",
            "[0 1 2 3] [4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au lieu de séparer les données aléatoirement, on les sépare selon des **groupes**.\n",
        "\n",
        "* Chaque \"groupe\" peut être une catégorie, un patient, un client, une machine, un site, etc.\n",
        "* L’idée : à chaque itération, **on laisse un groupe complet de côté pour tester**, et on entraîne le modèle sur tous les autres groupes.\n",
        "\n",
        "> Exemple : si vous faites de la prédiction sur des patients, vous voulez tester votre modèle sur des patients **jamais vus** plutôt que de mélanger les données de chaque patient entre train et test.\n",
        "\n",
        "* Évite le **faux sentiment de performance** que l’on obtient quand les données du même groupe se retrouvent à la fois dans l’entraînement et le test.\n",
        "* Important quand les observations sont **corrélées au sein d’un groupe**.\n",
        "* Donne une évaluation plus **réaliste** pour la généralisation sur de nouveaux groupes.\n",
        "\n",
        "---\n",
        "\n",
        "`groups` est un **vecteur (liste ou array)** qui associe **chaque observation à un groupe**.\n",
        "\n",
        "* Même longueur que `X` et `y`.\n",
        "* Chaque valeur indique à quel **groupe** appartient l’observation correspondante.\n",
        "\n",
        "> Exemple : si vous avez 10 observations et 3 patients (A, B, C), `groups` pourrait ressembler à :\n",
        "\n",
        "```python\n",
        "groups = ['A','A','A','B','B','B','C','C','C','C']\n",
        "```\n",
        "\n",
        "Ici :\n",
        "\n",
        "* Les 3 premières lignes → patient A\n",
        "* Les 3 suivantes → patient B\n",
        "* Les 4 dernières → patient C\n",
        "\n",
        "Lors de la validation croisée **LeaveOneGroupOut** :\n",
        "\n",
        "1. Le modèle va **laisser un groupe entier de côté** pour le test.\n",
        "2. Toutes les observations avec le même identifiant de groupe sont **testées ensemble**.\n",
        "3. Les autres groupes servent à **l’entraînement**.\n",
        "\n",
        "> Avec l’exemple ci-dessus :\n",
        "\n",
        "* Itération 1 → test = A, train = B+C\n",
        "* Itération 2 → test = B, train = A+C\n",
        "* Itération 3 → test = C, train = A+B\n",
        "\n",
        "---\n",
        "\n",
        "* Les groupes doivent être définis **avant la validation**, selon ce que vous voulez généraliser.\n",
        "* Très utile pour éviter que le modèle “triche” en voyant des données similaires de test dans le train.\n",
        "* Chaque groupe doit avoir **au moins une observation**, sinon LOGO ne pourra pas l’utiliser comme test.\n",
        "\n",
        "* Chaque test est **entièrement indépendant des autres groupes**.\n",
        "* Utile quand les groupes ont des caractéristiques internes similaires.\n",
        "* Plus fiable que le simple K-Fold si vos données sont **corrélées par groupe**.\n",
        "* Ne pas confondre avec le **LeaveOneOut classique** qui ignore les groupes.\n"
      ],
      "metadata": {
        "id": "4IfDLk49HPk6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXB4tTX0lasx"
      },
      "source": [
        "##### Leave P Groups Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr5k4V9GjioY",
        "outputId": "58072b24-6f32-49a2-9909-9e9ef22810a0"
      },
      "source": [
        "from sklearn.model_selection import LeavePGroupsOut\n",
        "\n",
        "X = np.arange(6)\n",
        "y = [1, 1, 1, 2, 2, 2]\n",
        "groups = [1, 1, 2, 2, 3, 3]\n",
        "lpgo = LeavePGroupsOut(n_groups=2)\n",
        "for train, test in lpgo.split(X, y, groups=groups):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 5] [0 1 2 3]\n",
            "[2 3] [0 1 4 5]\n",
            "[0 1] [2 3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imaginez que vous entraînez un modèle pour prédire les ventes dans différents magasins. Si votre modèle voit des données d’un magasin et qu’on le teste **sur ce même magasin**, il risque de “tricher” : il connaît déjà les habitudes locales.\n",
        "\n",
        "**LeavePGroupsOut** règle ce problème :\n",
        "\n",
        "* On **regroupe les données** (par exemple, chaque magasin = un groupe).\n",
        "* À chaque test, on **laisse de côté un ou plusieurs groupes** et on entraîne le modèle sur tous les autres.\n",
        "* On teste ensuite sur le ou les groupes laissés de côté, **jamais vus par le modèle**.\n",
        "\n",
        "✅ Vous savez exactement si votre modèle peut **généraliser à de nouveaux magasins, clients ou patients**.\n",
        "\n",
        "C’est comme étudier pour un examen, mais **tester vos connaissances sur des chapitres jamais vus en classe**."
      ],
      "metadata": {
        "id": "VmJ6XLUjL0mF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5rX0_0HmIOf"
      },
      "source": [
        "##### Group Shuffle Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d2GEBa_l7zU",
        "outputId": "7580ca37-1b65-406a-8ffd-56fe329b4b37"
      },
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]\n",
        "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"]\n",
        "groups = [1, 1, 2, 2, 3, 3, 4, 4]\n",
        "gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)\n",
        "for train, test in gss.split(X, y, groups=groups):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3] [4 5 6 7]\n",
            "[2 3 6 7] [0 1 4 5]\n",
            "[2 3 4 5] [0 1 6 7]\n",
            "[4 5 6 7] [0 1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intention :** éviter que les mêmes groupes apparaissent à la fois dans le train et dans le test.\n",
        "**Pourquoi c’est crucial ?** Parce que sinon on teste le modèle sur des données *qu’il a déjà vues sous une autre forme*, ce qui gonfle artificiellement les performances.\n",
        "\n",
        "Si un groupe va dans *train*, **l’ensemble de ses observations y vont**.\n",
        "Si un groupe va dans *test*, **aucune de ses observations n’est dans le train**.\n",
        "\n",
        "---\n",
        "\n",
        "1. Tu définis un vecteur `groups`\n",
        "   (ex : `groups = patient_id`, ou `machine_id`…).\n",
        "2. GroupShuffleSplit :\n",
        "\n",
        "   * mélange les groupes (pas les échantillons),\n",
        "   * sélectionne un pourcentage de groupes pour le train,\n",
        "   * le reste pour le test.\n",
        "\n",
        "Cela garantit **zéro contamination** entre train et test.\n",
        "\n",
        "---\n",
        "\n",
        "Supposons 10 machines → chacune produit 500 lignes de données.\n",
        "Tu veux que ton modèle détecte des anomalies.\n",
        "\n",
        "Avec un train/test split classique :\n",
        "\n",
        "* une même machine peut apparaître dans train **et** test → biais.\n",
        "\n",
        "Avec **GroupShuffleSplit** :\n",
        "\n",
        "* 8 machines dans train,\n",
        "* 2 machines dans test,\n",
        "* les 500 lignes de chaque machine restent ensemble.\n",
        "\n",
        "Résultat :\n",
        "**tu évalues la généralisation sur de vraies nouvelles machines**.\n",
        "\n",
        "Situations typiques :\n",
        "\n",
        "* données hiérarchiques ou corrélées,\n",
        "* plusieurs observations par entité,\n",
        "* temporel *sans* vouloir de split chronologique,\n",
        "* tout contexte où les échantillons au sein d’un groupe se ressemblent trop."
      ],
      "metadata": {
        "id": "lBJv5Q1yp9Sc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T47PEM0GovBl"
      },
      "source": [
        "#### Utilisation d'itérateurs de validation croisée pour diviser les ensembles d'entraînement et de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4XJtrXbnSQn",
        "outputId": "558fac34-219a-4541-a7f2-758165103d6e"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "X = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001])\n",
        "y = np.array([\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"])\n",
        "groups = np.array([1, 1, 2, 2, 3, 3, 4, 4])\n",
        "train_indx, test_indx = next(\n",
        "    GroupShuffleSplit(random_state=7).split(X, y, groups)\n",
        ")\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "X[train_indx], X[test_indx], y[train_indx], y[test_indx]\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6,), (2,))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `.split()` **ne renvoie pas directement les indices de lignes dans l’ordre**, ni “le premier” ou “le dernier” au sens mathématique, **il génère des paires d’indices (train, test) pour chaque division possible**.\n",
        "\n",
        "  * Chaque paire contient **tous les indices des lignes correspondantes**, pas juste un indice unique.\n",
        "\n",
        "* Exemple simple : si X a 5 lignes `[0,1,2,3,4]` et on fait 1 split :\n",
        "\n",
        "  ```python\n",
        "  gss = GroupShuffleSplit(n_splits=1, test_size=0.4, random_state=7)\n",
        "  it = gss.split(X, y, groups)\n",
        "  ```\n",
        "\n",
        "  * `it` est un générateur qui **produira une seule paire** de listes d’indices :\n",
        "\n",
        "    ```python\n",
        "    train_index = [0,2,4]\n",
        "    test_index  = [1,3]\n",
        "    ```\n",
        "\n",
        "> `next(it)` ne renvoie pas un seul “indice”, il renvoie **la première paire complète** d’indices (donc tous les indices pour l’entraînement et le test).\n",
        "\n",
        "---\n",
        "\n",
        "  * `next()` prend **la première sortie du générateur**, c’est-à-dire la **première paire train/test**.\n",
        "  * Mais cette “première sortie” contient **tous les indices pour chaque ensemble**, donc ce n’est pas juste un nombre ou un indice unique.\n",
        "\n",
        "* Si tu avais plusieurs splits (`n_splits=5`), chaque `next()` suivant te donnerait **la paire suivante** de train/test.\n",
        "\n",
        "---\n",
        "\n",
        "* Imagine un tiroir avec plusieurs **pochettes de cartes** : chaque pochette contient **toutes les cartes d’un jeu**.\n",
        "* `.split()` prépare toutes les pochettes.\n",
        "* `next()` prend la **première pochette entière**.\n",
        "* Les cartes à l’intérieur = tous les indices pour entraîner et tester."
      ],
      "metadata": {
        "id": "ZlB4-RZ7xGfA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3URpx972qcUH",
        "outputId": "3e7ecef1-8c65-415b-a7cb-3da30100246a"
      },
      "source": [
        "np.unique(groups[train_indx]), np.unique(groups[test_indx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 4]), array([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teQSrjtmrFu7"
      },
      "source": [
        "##### Time Series Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdXFfse3qlDj",
        "outputId": "ae704120-18b7-490b-ccce-352db95db5a8"
      },
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([1, 2, 3, 4, 5, 6])\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "print(tscv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeSeriesSplit(max_train_size=None, n_splits=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JKGIlEVrsFa",
        "outputId": "d180d16a-cbcc-4050-b450-e660a0536e2f"
      },
      "source": [
        "for train, test in tscv.split(X):\n",
        "  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2] [3]\n",
            "[0 1 2 3] [4]\n",
            "[0 1 2 3 4] [5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avec des données **chronologiques** (ventes, températures, capteurs, stock, etc.), il y a une contrainte : **on ne peut pas mélanger le passé et le futur**.\n",
        "\n",
        "* Exemple : tu ne peux pas utiliser les ventes de décembre pour prédire celles de janvier si ton modèle est censé être appliqué en temps réel.\n",
        "\n",
        "C’est là que **TimeSeriesSplit** devient utile.\n",
        "\n",
        "---\n",
        "\n",
        "### Qu’est-ce que TimeSeriesSplit ?\n",
        "\n",
        "C’est une **méthode de validation croisée adaptée aux séries temporelles**.\n",
        "Contrairement à un KFold classique qui mélange aléatoirement les données :\n",
        "\n",
        "* TimeSeriesSplit respecte **l’ordre chronologique**.\n",
        "* Chaque \"split\" utilise **le passé pour prédire le futur**.\n",
        "\n",
        "---\n",
        "\n",
        "### Comment ça fonctionne concrètement ?\n",
        "\n",
        "Supposons qu’on ait 9 observations et qu’on fasse `n_splits=3`. TimeSeriesSplit va créer 3 sous-ensembles d’entraînement et de test comme ceci :\n",
        "\n",
        "| Split | Train         | Test |\n",
        "| ----- | ------------- | ---- |\n",
        "| 1     | 0 1 2         | 3 4  |\n",
        "| 2     | 0 1 2 3 4     | 5 6  |\n",
        "| 3     | 0 1 2 3 4 5 6 | 7 8  |\n",
        "\n",
        "On voit que :\n",
        "\n",
        "* Le **train** inclut toujours les données antérieures au **test**.\n",
        "* Le **test** avance progressivement dans le temps.\n",
        "\n",
        "---\n",
        "\n",
        "### Exemple en Python\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import numpy as np\n",
        "\n",
        "X = np.arange(10).reshape(-1,1)  # features fictives\n",
        "y = np.arange(10)  # target fictive\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "```\n",
        "\n",
        "Sortie possible :\n",
        "\n",
        "```\n",
        "TRAIN: [0 1 2 3] TEST: [4 5]\n",
        "TRAIN: [0 1 2 3 4 5] TEST: [6 7]\n",
        "TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Pourquoi c’est utile pour vous\n",
        "\n",
        "* Permet de **tester des modèles prédictifs sur des séries temporelles** sans tricher avec le futur.\n",
        "* Aide à **évaluer la stabilité** du modèle au fil du temps.\n",
        "* S’intègre facilement dans **scikit-learn**, donc prêt pour les pipelines professionnels."
      ],
      "metadata": {
        "id": "aPSnn2w90_k9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wxnhcCMtygJ"
      },
      "source": [
        "[Source : Scikit Learn](https://https://scikit-learn.org/stable/modules/cross_validation.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPJKmXqwr3L7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}